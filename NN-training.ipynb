{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b948767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from math import sqrt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb87b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_price</th>\n",
       "      <th>numTracks</th>\n",
       "      <th>albumRelease</th>\n",
       "      <th>BC_friday</th>\n",
       "      <th>item_type_a</th>\n",
       "      <th>item_type_t</th>\n",
       "      <th>country_code_ad</th>\n",
       "      <th>country_code_ae</th>\n",
       "      <th>country_code_am</th>\n",
       "      <th>country_code_ar</th>\n",
       "      <th>country_code_at</th>\n",
       "      <th>country_code_au</th>\n",
       "      <th>country_code_aw</th>\n",
       "      <th>country_code_az</th>\n",
       "      <th>country_code_ba</th>\n",
       "      <th>country_code_bb</th>\n",
       "      <th>country_code_be</th>\n",
       "      <th>country_code_bg</th>\n",
       "      <th>country_code_bh</th>\n",
       "      <th>country_code_bm</th>\n",
       "      <th>country_code_bn</th>\n",
       "      <th>country_code_bo</th>\n",
       "      <th>country_code_br</th>\n",
       "      <th>country_code_bs</th>\n",
       "      <th>country_code_bw</th>\n",
       "      <th>country_code_by</th>\n",
       "      <th>country_code_c2</th>\n",
       "      <th>country_code_ca</th>\n",
       "      <th>country_code_ch</th>\n",
       "      <th>country_code_cl</th>\n",
       "      <th>country_code_cn</th>\n",
       "      <th>country_code_co</th>\n",
       "      <th>country_code_cr</th>\n",
       "      <th>country_code_cy</th>\n",
       "      <th>country_code_cz</th>\n",
       "      <th>country_code_de</th>\n",
       "      <th>country_code_dk</th>\n",
       "      <th>country_code_do</th>\n",
       "      <th>country_code_dz</th>\n",
       "      <th>country_code_ec</th>\n",
       "      <th>country_code_ee</th>\n",
       "      <th>country_code_eg</th>\n",
       "      <th>country_code_es</th>\n",
       "      <th>country_code_fi</th>\n",
       "      <th>country_code_fr</th>\n",
       "      <th>country_code_gb</th>\n",
       "      <th>country_code_ge</th>\n",
       "      <th>country_code_gf</th>\n",
       "      <th>country_code_gg</th>\n",
       "      <th>country_code_gi</th>\n",
       "      <th>country_code_gl</th>\n",
       "      <th>country_code_gp</th>\n",
       "      <th>country_code_gr</th>\n",
       "      <th>country_code_gt</th>\n",
       "      <th>country_code_gu</th>\n",
       "      <th>country_code_hk</th>\n",
       "      <th>country_code_hn</th>\n",
       "      <th>country_code_hr</th>\n",
       "      <th>country_code_hu</th>\n",
       "      <th>country_code_id</th>\n",
       "      <th>country_code_ie</th>\n",
       "      <th>country_code_il</th>\n",
       "      <th>country_code_im</th>\n",
       "      <th>country_code_in</th>\n",
       "      <th>country_code_is</th>\n",
       "      <th>country_code_it</th>\n",
       "      <th>country_code_je</th>\n",
       "      <th>country_code_jm</th>\n",
       "      <th>country_code_jo</th>\n",
       "      <th>country_code_jp</th>\n",
       "      <th>country_code_ke</th>\n",
       "      <th>country_code_kg</th>\n",
       "      <th>country_code_kh</th>\n",
       "      <th>country_code_kr</th>\n",
       "      <th>country_code_kw</th>\n",
       "      <th>country_code_kz</th>\n",
       "      <th>country_code_lb</th>\n",
       "      <th>country_code_li</th>\n",
       "      <th>country_code_lk</th>\n",
       "      <th>country_code_lt</th>\n",
       "      <th>country_code_lu</th>\n",
       "      <th>country_code_lv</th>\n",
       "      <th>country_code_ma</th>\n",
       "      <th>country_code_md</th>\n",
       "      <th>country_code_me</th>\n",
       "      <th>country_code_mk</th>\n",
       "      <th>country_code_mo</th>\n",
       "      <th>country_code_mq</th>\n",
       "      <th>country_code_mt</th>\n",
       "      <th>country_code_mu</th>\n",
       "      <th>country_code_mx</th>\n",
       "      <th>country_code_my</th>\n",
       "      <th>country_code_na</th>\n",
       "      <th>country_code_nc</th>\n",
       "      <th>country_code_ni</th>\n",
       "      <th>country_code_nl</th>\n",
       "      <th>country_code_no</th>\n",
       "      <th>country_code_nz</th>\n",
       "      <th>country_code_om</th>\n",
       "      <th>country_code_pa</th>\n",
       "      <th>country_code_pe</th>\n",
       "      <th>country_code_pf</th>\n",
       "      <th>country_code_ph</th>\n",
       "      <th>country_code_pk</th>\n",
       "      <th>country_code_pl</th>\n",
       "      <th>country_code_pr</th>\n",
       "      <th>country_code_ps</th>\n",
       "      <th>country_code_pt</th>\n",
       "      <th>country_code_py</th>\n",
       "      <th>country_code_qa</th>\n",
       "      <th>country_code_re</th>\n",
       "      <th>country_code_ro</th>\n",
       "      <th>country_code_rs</th>\n",
       "      <th>country_code_ru</th>\n",
       "      <th>country_code_sa</th>\n",
       "      <th>country_code_se</th>\n",
       "      <th>country_code_sg</th>\n",
       "      <th>country_code_si</th>\n",
       "      <th>country_code_sk</th>\n",
       "      <th>country_code_sn</th>\n",
       "      <th>country_code_sv</th>\n",
       "      <th>country_code_th</th>\n",
       "      <th>country_code_tn</th>\n",
       "      <th>country_code_tr</th>\n",
       "      <th>country_code_tt</th>\n",
       "      <th>country_code_tw</th>\n",
       "      <th>country_code_ua</th>\n",
       "      <th>country_code_ug</th>\n",
       "      <th>country_code_us</th>\n",
       "      <th>country_code_uy</th>\n",
       "      <th>country_code_ve</th>\n",
       "      <th>country_code_vn</th>\n",
       "      <th>country_code_xk</th>\n",
       "      <th>country_code_za</th>\n",
       "      <th>currency_AUD</th>\n",
       "      <th>currency_CAD</th>\n",
       "      <th>currency_CHF</th>\n",
       "      <th>currency_CZK</th>\n",
       "      <th>currency_DKK</th>\n",
       "      <th>currency_EUR</th>\n",
       "      <th>currency_GBP</th>\n",
       "      <th>currency_HKD</th>\n",
       "      <th>currency_HUF</th>\n",
       "      <th>currency_ILS</th>\n",
       "      <th>currency_JPY</th>\n",
       "      <th>currency_MXN</th>\n",
       "      <th>currency_NOK</th>\n",
       "      <th>currency_NZD</th>\n",
       "      <th>currency_PLN</th>\n",
       "      <th>currency_SEK</th>\n",
       "      <th>currency_SGD</th>\n",
       "      <th>currency_USD</th>\n",
       "      <th>genre_acoustic</th>\n",
       "      <th>genre_alternative</th>\n",
       "      <th>genre_ambient</th>\n",
       "      <th>genre_audiobooks</th>\n",
       "      <th>genre_blues</th>\n",
       "      <th>genre_classical</th>\n",
       "      <th>genre_comedy</th>\n",
       "      <th>genre_country</th>\n",
       "      <th>genre_devotional</th>\n",
       "      <th>genre_electronic</th>\n",
       "      <th>genre_experimental</th>\n",
       "      <th>genre_folk</th>\n",
       "      <th>genre_funk</th>\n",
       "      <th>genre_hip-hop-rap</th>\n",
       "      <th>genre_jazz</th>\n",
       "      <th>genre_kids</th>\n",
       "      <th>genre_latin</th>\n",
       "      <th>genre_metal</th>\n",
       "      <th>genre_other</th>\n",
       "      <th>genre_podcasts</th>\n",
       "      <th>genre_pop</th>\n",
       "      <th>genre_punk</th>\n",
       "      <th>genre_r-b-soul</th>\n",
       "      <th>genre_reggae</th>\n",
       "      <th>genre_rock</th>\n",
       "      <th>genre_soundtrack</th>\n",
       "      <th>genre_spoken-word</th>\n",
       "      <th>genre_world</th>\n",
       "      <th>inAlbum_in</th>\n",
       "      <th>inAlbum_is</th>\n",
       "      <th>inAlbum_not</th>\n",
       "      <th>tags_140</th>\n",
       "      <th>tags_2step</th>\n",
       "      <th>tags_80s</th>\n",
       "      <th>tags_acid</th>\n",
       "      <th>tags_acoustic</th>\n",
       "      <th>tags_afrobeat</th>\n",
       "      <th>tags_alternative</th>\n",
       "      <th>tags_alternativerock</th>\n",
       "      <th>tags_ambientelectronic</th>\n",
       "      <th>tags_americana</th>\n",
       "      <th>tags_atmospheric</th>\n",
       "      <th>tags_atmosphericblackmetal</th>\n",
       "      <th>tags_avantgarde</th>\n",
       "      <th>tags_bass</th>\n",
       "      <th>tags_bassmusic</th>\n",
       "      <th>tags_beats</th>\n",
       "      <th>tags_berlin</th>\n",
       "      <th>tags_blackmetal</th>\n",
       "      <th>tags_blues</th>\n",
       "      <th>tags_breakbeat</th>\n",
       "      <th>tags_breaks</th>\n",
       "      <th>tags_brokenbeat</th>\n",
       "      <th>tags_chicago</th>\n",
       "      <th>tags_chillout</th>\n",
       "      <th>tags_chillwave</th>\n",
       "      <th>tags_coldwave</th>\n",
       "      <th>tags_comedy</th>\n",
       "      <th>tags_dance</th>\n",
       "      <th>tags_darkambient</th>\n",
       "      <th>tags_darktechno</th>\n",
       "      <th>tags_darkwave</th>\n",
       "      <th>tags_deathmetal</th>\n",
       "      <th>tags_deephouse</th>\n",
       "      <th>tags_disco</th>\n",
       "      <th>tags_diy</th>\n",
       "      <th>tags_doom</th>\n",
       "      <th>tags_downtempo</th>\n",
       "      <th>tags_dreampop</th>\n",
       "      <th>tags_drone</th>\n",
       "      <th>tags_drumbass</th>\n",
       "      <th>tags_dub</th>\n",
       "      <th>tags_dubstep</th>\n",
       "      <th>tags_ebm</th>\n",
       "      <th>tags_edm</th>\n",
       "      <th>tags_electro</th>\n",
       "      <th>tags_electronic</th>\n",
       "      <th>tags_electronica</th>\n",
       "      <th>tags_experimental</th>\n",
       "      <th>tags_folk</th>\n",
       "      <th>tags_funk</th>\n",
       "      <th>tags_garage</th>\n",
       "      <th>tags_hardcore</th>\n",
       "      <th>tags_hardrock</th>\n",
       "      <th>tags_hardtechno</th>\n",
       "      <th>tags_hiphop</th>\n",
       "      <th>tags_hiphop/rap</th>\n",
       "      <th>tags_house</th>\n",
       "      <th>tags_idm</th>\n",
       "      <th>tags_indie</th>\n",
       "      <th>tags_indierock</th>\n",
       "      <th>tags_london</th>\n",
       "      <th>tags_losangeles</th>\n",
       "      <th>tags_melbourne</th>\n",
       "      <th>tags_metal</th>\n",
       "      <th>tags_newyork</th>\n",
       "      <th>tags_other</th>\n",
       "      <th>tags_paris</th>\n",
       "      <th>tags_poppunk</th>\n",
       "      <th>tags_progressiverock</th>\n",
       "      <th>tags_punk</th>\n",
       "      <th>tags_rb</th>\n",
       "      <th>tags_rb/soul</th>\n",
       "      <th>tags_rock</th>\n",
       "      <th>tags_spokenword</th>\n",
       "      <th>tags_techno</th>\n",
       "      <th>tags_unitedkingdom</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.69</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_price  numTracks  albumRelease  BC_friday  item_type_a  item_type_t  \\\n",
       "0        4.69        9.0             1          1            1            0   \n",
       "1        1.18        1.0             1          0            0            1   \n",
       "2        3.00        1.0             1          0            0            1   \n",
       "3        7.00        8.0             1          0            1            0   \n",
       "4        1.00        1.0             1          0            0            1   \n",
       "\n",
       "   country_code_ad  country_code_ae  country_code_am  country_code_ar  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_at  country_code_au  country_code_aw  country_code_az  \\\n",
       "0                0                0                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ba  country_code_bb  country_code_be  country_code_bg  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_bh  country_code_bm  country_code_bn  country_code_bo  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_br  country_code_bs  country_code_bw  country_code_by  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_c2  country_code_ca  country_code_ch  country_code_cl  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_cn  country_code_co  country_code_cr  country_code_cy  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_cz  country_code_de  country_code_dk  country_code_do  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_dz  country_code_ec  country_code_ee  country_code_eg  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_es  country_code_fi  country_code_fr  country_code_gb  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                1   \n",
       "\n",
       "   country_code_ge  country_code_gf  country_code_gg  country_code_gi  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_gl  country_code_gp  country_code_gr  country_code_gt  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_gu  country_code_hk  country_code_hn  country_code_hr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_hu  country_code_id  country_code_ie  country_code_il  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_im  country_code_in  country_code_is  country_code_it  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_je  country_code_jm  country_code_jo  country_code_jp  \\\n",
       "0                0                0                0                1   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ke  country_code_kg  country_code_kh  country_code_kr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_kw  country_code_kz  country_code_lb  country_code_li  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_lk  country_code_lt  country_code_lu  country_code_lv  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ma  country_code_md  country_code_me  country_code_mk  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_mo  country_code_mq  country_code_mt  country_code_mu  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_mx  country_code_my  country_code_na  country_code_nc  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ni  country_code_nl  country_code_no  country_code_nz  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_om  country_code_pa  country_code_pe  country_code_pf  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ph  country_code_pk  country_code_pl  country_code_pr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ps  country_code_pt  country_code_py  country_code_qa  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_re  country_code_ro  country_code_rs  country_code_ru  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_sa  country_code_se  country_code_sg  country_code_si  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_sk  country_code_sn  country_code_sv  country_code_th  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_tn  country_code_tr  country_code_tt  country_code_tw  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ua  country_code_ug  country_code_us  country_code_uy  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                1                0   \n",
       "3                0                0                1                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ve  country_code_vn  country_code_xk  country_code_za  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   currency_AUD  currency_CAD  currency_CHF  currency_CZK  currency_DKK  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_EUR  currency_GBP  currency_HKD  currency_HUF  currency_ILS  \\\n",
       "0             1             0             0             0             0   \n",
       "1             1             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_JPY  currency_MXN  currency_NOK  currency_NZD  currency_PLN  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_SEK  currency_SGD  currency_USD  genre_acoustic  \\\n",
       "0             0             0             0               0   \n",
       "1             0             0             0               0   \n",
       "2             0             0             1               0   \n",
       "3             0             0             1               0   \n",
       "4             0             0             1               0   \n",
       "\n",
       "   genre_alternative  genre_ambient  genre_audiobooks  genre_blues  \\\n",
       "0                  0              0                 0            0   \n",
       "1                  0              0                 0            0   \n",
       "2                  0              0                 0            0   \n",
       "3                  1              0                 0            0   \n",
       "4                  1              0                 0            0   \n",
       "\n",
       "   genre_classical  genre_comedy  genre_country  genre_devotional  \\\n",
       "0                0             0              0                 0   \n",
       "1                0             0              0                 0   \n",
       "2                0             0              0                 0   \n",
       "3                0             0              0                 0   \n",
       "4                0             0              0                 0   \n",
       "\n",
       "   genre_electronic  genre_experimental  genre_folk  genre_funk  \\\n",
       "0                 0                   1           0           0   \n",
       "1                 1                   0           0           0   \n",
       "2                 1                   0           0           0   \n",
       "3                 0                   0           0           0   \n",
       "4                 0                   0           0           0   \n",
       "\n",
       "   genre_hip-hop-rap  genre_jazz  genre_kids  genre_latin  genre_metal  \\\n",
       "0                  0           0           0            0            0   \n",
       "1                  0           0           0            0            0   \n",
       "2                  0           0           0            0            0   \n",
       "3                  0           0           0            0            0   \n",
       "4                  0           0           0            0            0   \n",
       "\n",
       "   genre_other  genre_podcasts  genre_pop  genre_punk  genre_r-b-soul  \\\n",
       "0            0               0          0           0               0   \n",
       "1            0               0          0           0               0   \n",
       "2            0               0          0           0               0   \n",
       "3            0               0          0           0               0   \n",
       "4            0               0          0           0               0   \n",
       "\n",
       "   genre_reggae  genre_rock  genre_soundtrack  genre_spoken-word  genre_world  \\\n",
       "0             0           0                 0                  0            0   \n",
       "1             0           0                 0                  0            0   \n",
       "2             0           0                 0                  0            0   \n",
       "3             0           0                 0                  0            0   \n",
       "4             0           0                 0                  0            0   \n",
       "\n",
       "   inAlbum_in  inAlbum_is  inAlbum_not  tags_140  tags_2step  tags_80s  \\\n",
       "0           0           1            0         0           0         0   \n",
       "1           1           0            0         0           0         0   \n",
       "2           0           0            1         0           0         0   \n",
       "3           0           1            0         0           0         0   \n",
       "4           1           0            0         0           0         0   \n",
       "\n",
       "   tags_acid  tags_acoustic  tags_afrobeat  tags_alternative  \\\n",
       "0          0              0              0                 0   \n",
       "1          1              0              0                 0   \n",
       "2          0              0              0                 0   \n",
       "3          0              0              0                 0   \n",
       "4          0              0              0                 0   \n",
       "\n",
       "   tags_alternativerock  tags_ambientelectronic  tags_americana  \\\n",
       "0                     0                       0               0   \n",
       "1                     0                       0               0   \n",
       "2                     0                       0               0   \n",
       "3                     0                       0               0   \n",
       "4                     0                       0               0   \n",
       "\n",
       "   tags_atmospheric  tags_atmosphericblackmetal  tags_avantgarde  tags_bass  \\\n",
       "0                 0                           0                0          0   \n",
       "1                 0                           0                0          0   \n",
       "2                 0                           0                0          0   \n",
       "3                 0                           0                0          0   \n",
       "4                 0                           0                0          0   \n",
       "\n",
       "   tags_bassmusic  tags_beats  tags_berlin  tags_blackmetal  tags_blues  \\\n",
       "0               0           0            0                0           0   \n",
       "1               0           0            0                0           0   \n",
       "2               0           0            0                0           0   \n",
       "3               0           0            0                0           0   \n",
       "4               0           0            0                0           0   \n",
       "\n",
       "   tags_breakbeat  tags_breaks  tags_brokenbeat  tags_chicago  tags_chillout  \\\n",
       "0               0            0                0             0              0   \n",
       "1               0            0                0             0              0   \n",
       "2               0            0                0             0              0   \n",
       "3               0            0                0             0              0   \n",
       "4               0            0                0             0              0   \n",
       "\n",
       "   tags_chillwave  tags_coldwave  tags_comedy  tags_dance  tags_darkambient  \\\n",
       "0               0              0            0           0                 0   \n",
       "1               0              0            0           0                 0   \n",
       "2               0              0            0           0                 0   \n",
       "3               0              0            0           0                 0   \n",
       "4               0              0            0           0                 0   \n",
       "\n",
       "   tags_darktechno  tags_darkwave  tags_deathmetal  tags_deephouse  \\\n",
       "0                0              0                0               0   \n",
       "1                0              0                0               0   \n",
       "2                0              0                0               0   \n",
       "3                0              0                0               0   \n",
       "4                0              0                0               0   \n",
       "\n",
       "   tags_disco  tags_diy  tags_doom  tags_downtempo  tags_dreampop  tags_drone  \\\n",
       "0           0         0          0               0              0           0   \n",
       "1           0         0          0               0              0           0   \n",
       "2           0         0          0               0              0           0   \n",
       "3           0         0          0               0              0           0   \n",
       "4           0         0          0               0              0           0   \n",
       "\n",
       "   tags_drumbass  tags_dub  tags_dubstep  tags_ebm  tags_edm  tags_electro  \\\n",
       "0              0         0             0         0         0             0   \n",
       "1              0         0             0         0         0             0   \n",
       "2              0         0             0         0         0             0   \n",
       "3              0         0             0         0         0             0   \n",
       "4              0         0             0         0         0             0   \n",
       "\n",
       "   tags_electronic  tags_electronica  tags_experimental  tags_folk  tags_funk  \\\n",
       "0                1                 0                  0          0          0   \n",
       "1                0                 0                  0          0          0   \n",
       "2                0                 0                  0          0          0   \n",
       "3                0                 0                  0          0          0   \n",
       "4                1                 0                  0          0          0   \n",
       "\n",
       "   tags_garage  tags_hardcore  tags_hardrock  tags_hardtechno  tags_hiphop  \\\n",
       "0            0              0              0                0            0   \n",
       "1            0              0              0                0            0   \n",
       "2            0              0              0                0            0   \n",
       "3            0              0              0                0            0   \n",
       "4            0              0              0                0            0   \n",
       "\n",
       "   tags_hiphop/rap  tags_house  tags_idm  tags_indie  tags_indierock  \\\n",
       "0                0           0         0           0               0   \n",
       "1                0           0         0           0               0   \n",
       "2                0           0         0           0               0   \n",
       "3                0           0         0           0               0   \n",
       "4                0           0         0           0               0   \n",
       "\n",
       "   tags_london  tags_losangeles  tags_melbourne  tags_metal  tags_newyork  \\\n",
       "0            0                0               0           0             0   \n",
       "1            0                0               0           0             0   \n",
       "2            0                0               0           0             0   \n",
       "3            0                0               0           0             0   \n",
       "4            0                0               0           0             0   \n",
       "\n",
       "   tags_other  tags_paris  tags_poppunk  tags_progressiverock  tags_punk  \\\n",
       "0           0           0             0                     0          0   \n",
       "1           0           0             0                     0          0   \n",
       "2           1           0             0                     0          0   \n",
       "3           1           0             0                     0          0   \n",
       "4           0           0             0                     0          0   \n",
       "\n",
       "   tags_rb  tags_rb/soul  tags_rock  tags_spokenword  tags_techno  \\\n",
       "0        0             0          0                0            0   \n",
       "1        0             0          0                0            0   \n",
       "2        0             0          0                0            0   \n",
       "3        0             0          0                0            0   \n",
       "4        0             0          0                0            0   \n",
       "\n",
       "   tags_unitedkingdom  day_0  day_1  day_2  day_3  day_4  day_5  day_6  \n",
       "0                   0      0      0      0      0      0      1      0  \n",
       "1                   0      0      0      1      0      0      0      0  \n",
       "2                   0      0      0      1      0      0      0      0  \n",
       "3                   0      0      0      0      0      1      0      0  \n",
       "4                   0      0      0      0      0      1      0      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('X_train.csv', index_col = 0)\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_train = X_train.drop(['index', 'item_type', 'country_code', 'currency', 'inAlbum', 'genre', 'tags', 'day',\n",
    "                       'coded_country_code', 'coded_currency', 'coded_genre', 'coded_tags'], axis = 1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17dd4609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_price</th>\n",
       "      <th>numTracks</th>\n",
       "      <th>albumRelease</th>\n",
       "      <th>BC_friday</th>\n",
       "      <th>item_type_a</th>\n",
       "      <th>item_type_t</th>\n",
       "      <th>country_code_ad</th>\n",
       "      <th>country_code_ae</th>\n",
       "      <th>country_code_am</th>\n",
       "      <th>country_code_ar</th>\n",
       "      <th>country_code_at</th>\n",
       "      <th>country_code_au</th>\n",
       "      <th>country_code_aw</th>\n",
       "      <th>country_code_az</th>\n",
       "      <th>country_code_ba</th>\n",
       "      <th>country_code_bb</th>\n",
       "      <th>country_code_be</th>\n",
       "      <th>country_code_bg</th>\n",
       "      <th>country_code_bh</th>\n",
       "      <th>country_code_bm</th>\n",
       "      <th>country_code_bn</th>\n",
       "      <th>country_code_bo</th>\n",
       "      <th>country_code_br</th>\n",
       "      <th>country_code_bs</th>\n",
       "      <th>country_code_bw</th>\n",
       "      <th>country_code_by</th>\n",
       "      <th>country_code_c2</th>\n",
       "      <th>country_code_ca</th>\n",
       "      <th>country_code_ch</th>\n",
       "      <th>country_code_cl</th>\n",
       "      <th>country_code_cn</th>\n",
       "      <th>country_code_co</th>\n",
       "      <th>country_code_cr</th>\n",
       "      <th>country_code_cy</th>\n",
       "      <th>country_code_cz</th>\n",
       "      <th>country_code_de</th>\n",
       "      <th>country_code_dk</th>\n",
       "      <th>country_code_do</th>\n",
       "      <th>country_code_dz</th>\n",
       "      <th>country_code_ec</th>\n",
       "      <th>country_code_ee</th>\n",
       "      <th>country_code_eg</th>\n",
       "      <th>country_code_es</th>\n",
       "      <th>country_code_fi</th>\n",
       "      <th>country_code_fr</th>\n",
       "      <th>country_code_gb</th>\n",
       "      <th>country_code_ge</th>\n",
       "      <th>country_code_gf</th>\n",
       "      <th>country_code_gg</th>\n",
       "      <th>country_code_gi</th>\n",
       "      <th>country_code_gl</th>\n",
       "      <th>country_code_gp</th>\n",
       "      <th>country_code_gr</th>\n",
       "      <th>country_code_gt</th>\n",
       "      <th>country_code_gu</th>\n",
       "      <th>country_code_hk</th>\n",
       "      <th>country_code_hn</th>\n",
       "      <th>country_code_hr</th>\n",
       "      <th>country_code_hu</th>\n",
       "      <th>country_code_id</th>\n",
       "      <th>country_code_ie</th>\n",
       "      <th>country_code_il</th>\n",
       "      <th>country_code_im</th>\n",
       "      <th>country_code_in</th>\n",
       "      <th>country_code_is</th>\n",
       "      <th>country_code_it</th>\n",
       "      <th>country_code_je</th>\n",
       "      <th>country_code_jm</th>\n",
       "      <th>country_code_jo</th>\n",
       "      <th>country_code_jp</th>\n",
       "      <th>country_code_ke</th>\n",
       "      <th>country_code_kg</th>\n",
       "      <th>country_code_kh</th>\n",
       "      <th>country_code_kr</th>\n",
       "      <th>country_code_kw</th>\n",
       "      <th>country_code_kz</th>\n",
       "      <th>country_code_lb</th>\n",
       "      <th>country_code_li</th>\n",
       "      <th>country_code_lk</th>\n",
       "      <th>country_code_lt</th>\n",
       "      <th>country_code_lu</th>\n",
       "      <th>country_code_lv</th>\n",
       "      <th>country_code_ma</th>\n",
       "      <th>country_code_md</th>\n",
       "      <th>country_code_me</th>\n",
       "      <th>country_code_mk</th>\n",
       "      <th>country_code_mo</th>\n",
       "      <th>country_code_mq</th>\n",
       "      <th>country_code_mt</th>\n",
       "      <th>country_code_mu</th>\n",
       "      <th>country_code_mx</th>\n",
       "      <th>country_code_my</th>\n",
       "      <th>country_code_na</th>\n",
       "      <th>country_code_nc</th>\n",
       "      <th>country_code_ni</th>\n",
       "      <th>country_code_nl</th>\n",
       "      <th>country_code_no</th>\n",
       "      <th>country_code_nz</th>\n",
       "      <th>country_code_om</th>\n",
       "      <th>country_code_pa</th>\n",
       "      <th>country_code_pe</th>\n",
       "      <th>country_code_pf</th>\n",
       "      <th>country_code_ph</th>\n",
       "      <th>country_code_pk</th>\n",
       "      <th>country_code_pl</th>\n",
       "      <th>country_code_pr</th>\n",
       "      <th>country_code_ps</th>\n",
       "      <th>country_code_pt</th>\n",
       "      <th>country_code_py</th>\n",
       "      <th>country_code_qa</th>\n",
       "      <th>country_code_re</th>\n",
       "      <th>country_code_ro</th>\n",
       "      <th>country_code_rs</th>\n",
       "      <th>country_code_ru</th>\n",
       "      <th>country_code_sa</th>\n",
       "      <th>country_code_se</th>\n",
       "      <th>country_code_sg</th>\n",
       "      <th>country_code_si</th>\n",
       "      <th>country_code_sk</th>\n",
       "      <th>country_code_sn</th>\n",
       "      <th>country_code_sv</th>\n",
       "      <th>country_code_th</th>\n",
       "      <th>country_code_tn</th>\n",
       "      <th>country_code_tr</th>\n",
       "      <th>country_code_tt</th>\n",
       "      <th>country_code_tw</th>\n",
       "      <th>country_code_ua</th>\n",
       "      <th>country_code_ug</th>\n",
       "      <th>country_code_us</th>\n",
       "      <th>country_code_uy</th>\n",
       "      <th>country_code_ve</th>\n",
       "      <th>country_code_vn</th>\n",
       "      <th>country_code_xk</th>\n",
       "      <th>country_code_za</th>\n",
       "      <th>currency_AUD</th>\n",
       "      <th>currency_CAD</th>\n",
       "      <th>currency_CHF</th>\n",
       "      <th>currency_CZK</th>\n",
       "      <th>currency_DKK</th>\n",
       "      <th>currency_EUR</th>\n",
       "      <th>currency_GBP</th>\n",
       "      <th>currency_HKD</th>\n",
       "      <th>currency_HUF</th>\n",
       "      <th>currency_ILS</th>\n",
       "      <th>currency_JPY</th>\n",
       "      <th>currency_MXN</th>\n",
       "      <th>currency_NOK</th>\n",
       "      <th>currency_NZD</th>\n",
       "      <th>currency_PLN</th>\n",
       "      <th>currency_SEK</th>\n",
       "      <th>currency_SGD</th>\n",
       "      <th>currency_USD</th>\n",
       "      <th>genre_acoustic</th>\n",
       "      <th>genre_alternative</th>\n",
       "      <th>genre_ambient</th>\n",
       "      <th>genre_audiobooks</th>\n",
       "      <th>genre_blues</th>\n",
       "      <th>genre_classical</th>\n",
       "      <th>genre_comedy</th>\n",
       "      <th>genre_country</th>\n",
       "      <th>genre_devotional</th>\n",
       "      <th>genre_electronic</th>\n",
       "      <th>genre_experimental</th>\n",
       "      <th>genre_folk</th>\n",
       "      <th>genre_funk</th>\n",
       "      <th>genre_hip-hop-rap</th>\n",
       "      <th>genre_jazz</th>\n",
       "      <th>genre_kids</th>\n",
       "      <th>genre_latin</th>\n",
       "      <th>genre_metal</th>\n",
       "      <th>genre_other</th>\n",
       "      <th>genre_podcasts</th>\n",
       "      <th>genre_pop</th>\n",
       "      <th>genre_punk</th>\n",
       "      <th>genre_r-b-soul</th>\n",
       "      <th>genre_reggae</th>\n",
       "      <th>genre_rock</th>\n",
       "      <th>genre_soundtrack</th>\n",
       "      <th>genre_spoken-word</th>\n",
       "      <th>genre_world</th>\n",
       "      <th>inAlbum_in</th>\n",
       "      <th>inAlbum_is</th>\n",
       "      <th>inAlbum_not</th>\n",
       "      <th>tags_140</th>\n",
       "      <th>tags_2step</th>\n",
       "      <th>tags_80s</th>\n",
       "      <th>tags_acid</th>\n",
       "      <th>tags_acoustic</th>\n",
       "      <th>tags_afrobeat</th>\n",
       "      <th>tags_alternative</th>\n",
       "      <th>tags_alternativerock</th>\n",
       "      <th>tags_ambientelectronic</th>\n",
       "      <th>tags_americana</th>\n",
       "      <th>tags_atmospheric</th>\n",
       "      <th>tags_atmosphericblackmetal</th>\n",
       "      <th>tags_avantgarde</th>\n",
       "      <th>tags_bass</th>\n",
       "      <th>tags_bassmusic</th>\n",
       "      <th>tags_beats</th>\n",
       "      <th>tags_berlin</th>\n",
       "      <th>tags_blackmetal</th>\n",
       "      <th>tags_blues</th>\n",
       "      <th>tags_breakbeat</th>\n",
       "      <th>tags_breaks</th>\n",
       "      <th>tags_brokenbeat</th>\n",
       "      <th>tags_chicago</th>\n",
       "      <th>tags_chillout</th>\n",
       "      <th>tags_chillwave</th>\n",
       "      <th>tags_coldwave</th>\n",
       "      <th>tags_comedy</th>\n",
       "      <th>tags_dance</th>\n",
       "      <th>tags_darkambient</th>\n",
       "      <th>tags_darktechno</th>\n",
       "      <th>tags_darkwave</th>\n",
       "      <th>tags_deathmetal</th>\n",
       "      <th>tags_deephouse</th>\n",
       "      <th>tags_disco</th>\n",
       "      <th>tags_diy</th>\n",
       "      <th>tags_doom</th>\n",
       "      <th>tags_downtempo</th>\n",
       "      <th>tags_dreampop</th>\n",
       "      <th>tags_drone</th>\n",
       "      <th>tags_drumbass</th>\n",
       "      <th>tags_dub</th>\n",
       "      <th>tags_dubstep</th>\n",
       "      <th>tags_ebm</th>\n",
       "      <th>tags_edm</th>\n",
       "      <th>tags_electro</th>\n",
       "      <th>tags_electronic</th>\n",
       "      <th>tags_electronica</th>\n",
       "      <th>tags_experimental</th>\n",
       "      <th>tags_folk</th>\n",
       "      <th>tags_funk</th>\n",
       "      <th>tags_garage</th>\n",
       "      <th>tags_hardcore</th>\n",
       "      <th>tags_hardrock</th>\n",
       "      <th>tags_hardtechno</th>\n",
       "      <th>tags_hiphop</th>\n",
       "      <th>tags_hiphop/rap</th>\n",
       "      <th>tags_house</th>\n",
       "      <th>tags_idm</th>\n",
       "      <th>tags_indie</th>\n",
       "      <th>tags_indierock</th>\n",
       "      <th>tags_london</th>\n",
       "      <th>tags_losangeles</th>\n",
       "      <th>tags_melbourne</th>\n",
       "      <th>tags_metal</th>\n",
       "      <th>tags_newyork</th>\n",
       "      <th>tags_other</th>\n",
       "      <th>tags_paris</th>\n",
       "      <th>tags_poppunk</th>\n",
       "      <th>tags_progressiverock</th>\n",
       "      <th>tags_punk</th>\n",
       "      <th>tags_rb</th>\n",
       "      <th>tags_rb/soul</th>\n",
       "      <th>tags_rock</th>\n",
       "      <th>tags_spokenword</th>\n",
       "      <th>tags_techno</th>\n",
       "      <th>tags_unitedkingdom</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_price  numTracks  albumRelease  BC_friday  item_type_a  item_type_t  \\\n",
       "0        1.78        1.0             1          0            0            1   \n",
       "1        2.00        2.0             1          0            1            0   \n",
       "2        9.00       10.0             1          0            1            0   \n",
       "3        6.00        5.0             1          0            1            0   \n",
       "4        5.15        4.0             2          1            1            0   \n",
       "\n",
       "   country_code_ad  country_code_ae  country_code_am  country_code_ar  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_at  country_code_au  country_code_aw  country_code_az  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ba  country_code_bb  country_code_be  country_code_bg  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_bh  country_code_bm  country_code_bn  country_code_bo  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_br  country_code_bs  country_code_bw  country_code_by  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_c2  country_code_ca  country_code_ch  country_code_cl  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_cn  country_code_co  country_code_cr  country_code_cy  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_cz  country_code_de  country_code_dk  country_code_do  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_dz  country_code_ec  country_code_ee  country_code_eg  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_es  country_code_fi  country_code_fr  country_code_gb  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                1                0   \n",
       "2                0                0                0                1   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                1   \n",
       "\n",
       "   country_code_ge  country_code_gf  country_code_gg  country_code_gi  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_gl  country_code_gp  country_code_gr  country_code_gt  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_gu  country_code_hk  country_code_hn  country_code_hr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_hu  country_code_id  country_code_ie  country_code_il  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_im  country_code_in  country_code_is  country_code_it  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_je  country_code_jm  country_code_jo  country_code_jp  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ke  country_code_kg  country_code_kh  country_code_kr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_kw  country_code_kz  country_code_lb  country_code_li  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_lk  country_code_lt  country_code_lu  country_code_lv  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ma  country_code_md  country_code_me  country_code_mk  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_mo  country_code_mq  country_code_mt  country_code_mu  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_mx  country_code_my  country_code_na  country_code_nc  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ni  country_code_nl  country_code_no  country_code_nz  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_om  country_code_pa  country_code_pe  country_code_pf  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ph  country_code_pk  country_code_pl  country_code_pr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ps  country_code_pt  country_code_py  country_code_qa  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_re  country_code_ro  country_code_rs  country_code_ru  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_sa  country_code_se  country_code_sg  country_code_si  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_sk  country_code_sn  country_code_sv  country_code_th  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_tn  country_code_tr  country_code_tt  country_code_tw  \\\n",
       "0                0                0                0                1   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ua  country_code_ug  country_code_us  country_code_uy  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                1                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ve  country_code_vn  country_code_xk  country_code_za  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   currency_AUD  currency_CAD  currency_CHF  currency_CZK  currency_DKK  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_EUR  currency_GBP  currency_HKD  currency_HUF  currency_ILS  \\\n",
       "0             1             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             1             0             0             0   \n",
       "\n",
       "   currency_JPY  currency_MXN  currency_NOK  currency_NZD  currency_PLN  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_SEK  currency_SGD  currency_USD  genre_acoustic  \\\n",
       "0             0             0             0               0   \n",
       "1             0             0             1               0   \n",
       "2             0             0             1               0   \n",
       "3             0             0             1               0   \n",
       "4             0             0             0               0   \n",
       "\n",
       "   genre_alternative  genre_ambient  genre_audiobooks  genre_blues  \\\n",
       "0                  0              0                 0            0   \n",
       "1                  0              0                 0            0   \n",
       "2                  1              0                 0            0   \n",
       "3                  0              0                 0            0   \n",
       "4                  0              0                 0            0   \n",
       "\n",
       "   genre_classical  genre_comedy  genre_country  genre_devotional  \\\n",
       "0                0             0              0                 0   \n",
       "1                0             0              0                 0   \n",
       "2                0             0              0                 0   \n",
       "3                0             0              0                 0   \n",
       "4                0             0              0                 0   \n",
       "\n",
       "   genre_electronic  genre_experimental  genre_folk  genre_funk  \\\n",
       "0                 1                   0           0           0   \n",
       "1                 0                   0           0           0   \n",
       "2                 0                   0           0           0   \n",
       "3                 1                   0           0           0   \n",
       "4                 1                   0           0           0   \n",
       "\n",
       "   genre_hip-hop-rap  genre_jazz  genre_kids  genre_latin  genre_metal  \\\n",
       "0                  0           0           0            0            0   \n",
       "1                  0           0           0            0            0   \n",
       "2                  0           0           0            0            0   \n",
       "3                  0           0           0            0            0   \n",
       "4                  0           0           0            0            0   \n",
       "\n",
       "   genre_other  genre_podcasts  genre_pop  genre_punk  genre_r-b-soul  \\\n",
       "0            0               0          0           0               0   \n",
       "1            1               0          0           0               0   \n",
       "2            0               0          0           0               0   \n",
       "3            0               0          0           0               0   \n",
       "4            0               0          0           0               0   \n",
       "\n",
       "   genre_reggae  genre_rock  genre_soundtrack  genre_spoken-word  genre_world  \\\n",
       "0             0           0                 0                  0            0   \n",
       "1             0           0                 0                  0            0   \n",
       "2             0           0                 0                  0            0   \n",
       "3             0           0                 0                  0            0   \n",
       "4             0           0                 0                  0            0   \n",
       "\n",
       "   inAlbum_in  inAlbum_is  inAlbum_not  tags_140  tags_2step  tags_80s  \\\n",
       "0           1           0            0         0           0         0   \n",
       "1           0           1            0         0           0         0   \n",
       "2           0           1            0         0           0         0   \n",
       "3           0           1            0         0           0         0   \n",
       "4           0           1            0         0           0         0   \n",
       "\n",
       "   tags_acid  tags_acoustic  tags_afrobeat  tags_alternative  \\\n",
       "0          0              0              0                 0   \n",
       "1          0              0              0                 0   \n",
       "2          0              0              0                 0   \n",
       "3          0              0              0                 0   \n",
       "4          0              0              0                 0   \n",
       "\n",
       "   tags_alternativerock  tags_ambientelectronic  tags_americana  \\\n",
       "0                     0                       0               0   \n",
       "1                     0                       0               0   \n",
       "2                     0                       0               0   \n",
       "3                     0                       0               0   \n",
       "4                     0                       0               0   \n",
       "\n",
       "   tags_atmospheric  tags_atmosphericblackmetal  tags_avantgarde  tags_bass  \\\n",
       "0                 0                           0                0          0   \n",
       "1                 0                           0                0          0   \n",
       "2                 0                           0                0          0   \n",
       "3                 0                           0                0          0   \n",
       "4                 0                           0                0          0   \n",
       "\n",
       "   tags_bassmusic  tags_beats  tags_berlin  tags_blackmetal  tags_blues  \\\n",
       "0               0           0            0                0           0   \n",
       "1               0           0            0                0           0   \n",
       "2               0           0            0                0           0   \n",
       "3               0           0            0                0           0   \n",
       "4               0           0            0                0           0   \n",
       "\n",
       "   tags_breakbeat  tags_breaks  tags_brokenbeat  tags_chicago  tags_chillout  \\\n",
       "0               0            0                0             0              0   \n",
       "1               0            0                0             0              0   \n",
       "2               0            0                0             0              0   \n",
       "3               0            0                0             0              0   \n",
       "4               0            0                0             0              0   \n",
       "\n",
       "   tags_chillwave  tags_coldwave  tags_comedy  tags_dance  tags_darkambient  \\\n",
       "0               0              0            0           0                 0   \n",
       "1               0              0            0           0                 0   \n",
       "2               0              0            0           0                 0   \n",
       "3               0              0            0           1                 0   \n",
       "4               0              0            0           0                 0   \n",
       "\n",
       "   tags_darktechno  tags_darkwave  tags_deathmetal  tags_deephouse  \\\n",
       "0                0              0                0               0   \n",
       "1                0              0                0               0   \n",
       "2                0              0                0               0   \n",
       "3                0              0                0               0   \n",
       "4                0              0                0               0   \n",
       "\n",
       "   tags_disco  tags_diy  tags_doom  tags_downtempo  tags_dreampop  tags_drone  \\\n",
       "0           0         0          0               0              0           0   \n",
       "1           0         0          0               0              0           0   \n",
       "2           0         0          0               0              0           0   \n",
       "3           0         0          0               0              0           0   \n",
       "4           0         0          0               0              0           0   \n",
       "\n",
       "   tags_drumbass  tags_dub  tags_dubstep  tags_ebm  tags_edm  tags_electro  \\\n",
       "0              0         0             0         0         0             0   \n",
       "1              1         0             0         0         0             0   \n",
       "2              0         0             0         0         0             0   \n",
       "3              0         0             0         0         0             0   \n",
       "4              0         0             0         0         0             0   \n",
       "\n",
       "   tags_electronic  tags_electronica  tags_experimental  tags_folk  tags_funk  \\\n",
       "0                1                 0                  0          0          0   \n",
       "1                0                 0                  0          0          0   \n",
       "2                0                 0                  0          0          0   \n",
       "3                0                 0                  0          0          0   \n",
       "4                0                 0                  0          0          0   \n",
       "\n",
       "   tags_garage  tags_hardcore  tags_hardrock  tags_hardtechno  tags_hiphop  \\\n",
       "0            0              0              0                0            0   \n",
       "1            0              0              0                0            0   \n",
       "2            0              0              0                0            0   \n",
       "3            0              0              0                0            0   \n",
       "4            0              0              0                0            0   \n",
       "\n",
       "   tags_hiphop/rap  tags_house  tags_idm  tags_indie  tags_indierock  \\\n",
       "0                0           0         0           0               0   \n",
       "1                0           0         0           0               0   \n",
       "2                0           0         0           0               0   \n",
       "3                0           0         0           0               0   \n",
       "4                0           0         0           0               0   \n",
       "\n",
       "   tags_london  tags_losangeles  tags_melbourne  tags_metal  tags_newyork  \\\n",
       "0            0                0               0           0             0   \n",
       "1            0                0               0           0             0   \n",
       "2            0                0               0           0             0   \n",
       "3            0                0               0           0             0   \n",
       "4            0                0               0           0             0   \n",
       "\n",
       "   tags_other  tags_paris  tags_poppunk  tags_progressiverock  tags_punk  \\\n",
       "0           0           0             0                     0          0   \n",
       "1           0           0             0                     0          0   \n",
       "2           1           0             0                     0          0   \n",
       "3           0           0             0                     0          0   \n",
       "4           1           0             0                     0          0   \n",
       "\n",
       "   tags_rb  tags_rb/soul  tags_rock  tags_spokenword  tags_techno  \\\n",
       "0        0             0          0                0            0   \n",
       "1        0             0          0                0            0   \n",
       "2        0             0          0                0            0   \n",
       "3        0             0          0                0            0   \n",
       "4        0             0          0                0            0   \n",
       "\n",
       "   tags_unitedkingdom  day_0  day_1  day_2  day_3  day_4  day_5  day_6  \n",
       "0                   0      0      0      1      0      0      0      0  \n",
       "1                   0      0      0      0      0      1      0      0  \n",
       "2                   0      0      1      0      0      0      0      0  \n",
       "3                   0      0      0      0      0      0      0      1  \n",
       "4                   0      0      0      0      0      0      1      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = pd.read_csv('X_valid.csv', index_col = 0)\n",
    "X_valid = X_valid.reset_index(drop = True)\n",
    "X_valid = X_valid.drop(['index', 'item_type', 'country_code', 'currency', 'inAlbum', 'genre', 'tags', 'day',\n",
    "                       'coded_country_code', 'coded_currency', 'coded_genre', 'coded_tags'], axis = 1)\n",
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9771ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_price</th>\n",
       "      <th>numTracks</th>\n",
       "      <th>albumRelease</th>\n",
       "      <th>BC_friday</th>\n",
       "      <th>item_type_a</th>\n",
       "      <th>item_type_t</th>\n",
       "      <th>country_code_ad</th>\n",
       "      <th>country_code_ae</th>\n",
       "      <th>country_code_am</th>\n",
       "      <th>country_code_ar</th>\n",
       "      <th>country_code_at</th>\n",
       "      <th>country_code_au</th>\n",
       "      <th>country_code_aw</th>\n",
       "      <th>country_code_az</th>\n",
       "      <th>country_code_ba</th>\n",
       "      <th>country_code_bb</th>\n",
       "      <th>country_code_be</th>\n",
       "      <th>country_code_bg</th>\n",
       "      <th>country_code_bh</th>\n",
       "      <th>country_code_bm</th>\n",
       "      <th>country_code_bn</th>\n",
       "      <th>country_code_bo</th>\n",
       "      <th>country_code_br</th>\n",
       "      <th>country_code_bs</th>\n",
       "      <th>country_code_bw</th>\n",
       "      <th>country_code_by</th>\n",
       "      <th>country_code_c2</th>\n",
       "      <th>country_code_ca</th>\n",
       "      <th>country_code_ch</th>\n",
       "      <th>country_code_cl</th>\n",
       "      <th>country_code_cn</th>\n",
       "      <th>country_code_co</th>\n",
       "      <th>country_code_cr</th>\n",
       "      <th>country_code_cy</th>\n",
       "      <th>country_code_cz</th>\n",
       "      <th>country_code_de</th>\n",
       "      <th>country_code_dk</th>\n",
       "      <th>country_code_do</th>\n",
       "      <th>country_code_dz</th>\n",
       "      <th>country_code_ec</th>\n",
       "      <th>country_code_ee</th>\n",
       "      <th>country_code_eg</th>\n",
       "      <th>country_code_es</th>\n",
       "      <th>country_code_fi</th>\n",
       "      <th>country_code_fr</th>\n",
       "      <th>country_code_gb</th>\n",
       "      <th>country_code_ge</th>\n",
       "      <th>country_code_gf</th>\n",
       "      <th>country_code_gg</th>\n",
       "      <th>country_code_gi</th>\n",
       "      <th>country_code_gl</th>\n",
       "      <th>country_code_gp</th>\n",
       "      <th>country_code_gr</th>\n",
       "      <th>country_code_gt</th>\n",
       "      <th>country_code_gu</th>\n",
       "      <th>country_code_hk</th>\n",
       "      <th>country_code_hn</th>\n",
       "      <th>country_code_hr</th>\n",
       "      <th>country_code_hu</th>\n",
       "      <th>country_code_id</th>\n",
       "      <th>country_code_ie</th>\n",
       "      <th>country_code_il</th>\n",
       "      <th>country_code_im</th>\n",
       "      <th>country_code_in</th>\n",
       "      <th>country_code_is</th>\n",
       "      <th>country_code_it</th>\n",
       "      <th>country_code_je</th>\n",
       "      <th>country_code_jm</th>\n",
       "      <th>country_code_jo</th>\n",
       "      <th>country_code_jp</th>\n",
       "      <th>country_code_ke</th>\n",
       "      <th>country_code_kg</th>\n",
       "      <th>country_code_kh</th>\n",
       "      <th>country_code_kr</th>\n",
       "      <th>country_code_kw</th>\n",
       "      <th>country_code_kz</th>\n",
       "      <th>country_code_lb</th>\n",
       "      <th>country_code_li</th>\n",
       "      <th>country_code_lk</th>\n",
       "      <th>country_code_lt</th>\n",
       "      <th>country_code_lu</th>\n",
       "      <th>country_code_lv</th>\n",
       "      <th>country_code_ma</th>\n",
       "      <th>country_code_md</th>\n",
       "      <th>country_code_me</th>\n",
       "      <th>country_code_mk</th>\n",
       "      <th>country_code_mo</th>\n",
       "      <th>country_code_mq</th>\n",
       "      <th>country_code_mt</th>\n",
       "      <th>country_code_mu</th>\n",
       "      <th>country_code_mx</th>\n",
       "      <th>country_code_my</th>\n",
       "      <th>country_code_na</th>\n",
       "      <th>country_code_nc</th>\n",
       "      <th>country_code_ni</th>\n",
       "      <th>country_code_nl</th>\n",
       "      <th>country_code_no</th>\n",
       "      <th>country_code_nz</th>\n",
       "      <th>country_code_om</th>\n",
       "      <th>country_code_pa</th>\n",
       "      <th>country_code_pe</th>\n",
       "      <th>country_code_pf</th>\n",
       "      <th>country_code_ph</th>\n",
       "      <th>country_code_pk</th>\n",
       "      <th>country_code_pl</th>\n",
       "      <th>country_code_pr</th>\n",
       "      <th>country_code_ps</th>\n",
       "      <th>country_code_pt</th>\n",
       "      <th>country_code_py</th>\n",
       "      <th>country_code_qa</th>\n",
       "      <th>country_code_re</th>\n",
       "      <th>country_code_ro</th>\n",
       "      <th>country_code_rs</th>\n",
       "      <th>country_code_ru</th>\n",
       "      <th>country_code_sa</th>\n",
       "      <th>country_code_se</th>\n",
       "      <th>country_code_sg</th>\n",
       "      <th>country_code_si</th>\n",
       "      <th>country_code_sk</th>\n",
       "      <th>country_code_sn</th>\n",
       "      <th>country_code_sv</th>\n",
       "      <th>country_code_th</th>\n",
       "      <th>country_code_tn</th>\n",
       "      <th>country_code_tr</th>\n",
       "      <th>country_code_tt</th>\n",
       "      <th>country_code_tw</th>\n",
       "      <th>country_code_ua</th>\n",
       "      <th>country_code_ug</th>\n",
       "      <th>country_code_us</th>\n",
       "      <th>country_code_uy</th>\n",
       "      <th>country_code_ve</th>\n",
       "      <th>country_code_vn</th>\n",
       "      <th>country_code_xk</th>\n",
       "      <th>country_code_za</th>\n",
       "      <th>currency_AUD</th>\n",
       "      <th>currency_CAD</th>\n",
       "      <th>currency_CHF</th>\n",
       "      <th>currency_CZK</th>\n",
       "      <th>currency_DKK</th>\n",
       "      <th>currency_EUR</th>\n",
       "      <th>currency_GBP</th>\n",
       "      <th>currency_HKD</th>\n",
       "      <th>currency_HUF</th>\n",
       "      <th>currency_ILS</th>\n",
       "      <th>currency_JPY</th>\n",
       "      <th>currency_MXN</th>\n",
       "      <th>currency_NOK</th>\n",
       "      <th>currency_NZD</th>\n",
       "      <th>currency_PLN</th>\n",
       "      <th>currency_SEK</th>\n",
       "      <th>currency_SGD</th>\n",
       "      <th>currency_USD</th>\n",
       "      <th>genre_acoustic</th>\n",
       "      <th>genre_alternative</th>\n",
       "      <th>genre_ambient</th>\n",
       "      <th>genre_audiobooks</th>\n",
       "      <th>genre_blues</th>\n",
       "      <th>genre_classical</th>\n",
       "      <th>genre_comedy</th>\n",
       "      <th>genre_country</th>\n",
       "      <th>genre_devotional</th>\n",
       "      <th>genre_electronic</th>\n",
       "      <th>genre_experimental</th>\n",
       "      <th>genre_folk</th>\n",
       "      <th>genre_funk</th>\n",
       "      <th>genre_hip-hop-rap</th>\n",
       "      <th>genre_jazz</th>\n",
       "      <th>genre_kids</th>\n",
       "      <th>genre_latin</th>\n",
       "      <th>genre_metal</th>\n",
       "      <th>genre_other</th>\n",
       "      <th>genre_podcasts</th>\n",
       "      <th>genre_pop</th>\n",
       "      <th>genre_punk</th>\n",
       "      <th>genre_r-b-soul</th>\n",
       "      <th>genre_reggae</th>\n",
       "      <th>genre_rock</th>\n",
       "      <th>genre_soundtrack</th>\n",
       "      <th>genre_spoken-word</th>\n",
       "      <th>genre_world</th>\n",
       "      <th>inAlbum_in</th>\n",
       "      <th>inAlbum_is</th>\n",
       "      <th>inAlbum_not</th>\n",
       "      <th>tags_140</th>\n",
       "      <th>tags_2step</th>\n",
       "      <th>tags_80s</th>\n",
       "      <th>tags_acid</th>\n",
       "      <th>tags_acoustic</th>\n",
       "      <th>tags_afrobeat</th>\n",
       "      <th>tags_alternative</th>\n",
       "      <th>tags_alternativerock</th>\n",
       "      <th>tags_ambientelectronic</th>\n",
       "      <th>tags_americana</th>\n",
       "      <th>tags_atmospheric</th>\n",
       "      <th>tags_atmosphericblackmetal</th>\n",
       "      <th>tags_avantgarde</th>\n",
       "      <th>tags_bass</th>\n",
       "      <th>tags_bassmusic</th>\n",
       "      <th>tags_beats</th>\n",
       "      <th>tags_berlin</th>\n",
       "      <th>tags_blackmetal</th>\n",
       "      <th>tags_blues</th>\n",
       "      <th>tags_breakbeat</th>\n",
       "      <th>tags_breaks</th>\n",
       "      <th>tags_brokenbeat</th>\n",
       "      <th>tags_chicago</th>\n",
       "      <th>tags_chillout</th>\n",
       "      <th>tags_chillwave</th>\n",
       "      <th>tags_coldwave</th>\n",
       "      <th>tags_comedy</th>\n",
       "      <th>tags_dance</th>\n",
       "      <th>tags_darkambient</th>\n",
       "      <th>tags_darktechno</th>\n",
       "      <th>tags_darkwave</th>\n",
       "      <th>tags_deathmetal</th>\n",
       "      <th>tags_deephouse</th>\n",
       "      <th>tags_disco</th>\n",
       "      <th>tags_diy</th>\n",
       "      <th>tags_doom</th>\n",
       "      <th>tags_downtempo</th>\n",
       "      <th>tags_dreampop</th>\n",
       "      <th>tags_drone</th>\n",
       "      <th>tags_drumbass</th>\n",
       "      <th>tags_dub</th>\n",
       "      <th>tags_dubstep</th>\n",
       "      <th>tags_ebm</th>\n",
       "      <th>tags_edm</th>\n",
       "      <th>tags_electro</th>\n",
       "      <th>tags_electronic</th>\n",
       "      <th>tags_electronica</th>\n",
       "      <th>tags_experimental</th>\n",
       "      <th>tags_folk</th>\n",
       "      <th>tags_funk</th>\n",
       "      <th>tags_garage</th>\n",
       "      <th>tags_hardcore</th>\n",
       "      <th>tags_hardrock</th>\n",
       "      <th>tags_hardtechno</th>\n",
       "      <th>tags_hiphop</th>\n",
       "      <th>tags_hiphop/rap</th>\n",
       "      <th>tags_house</th>\n",
       "      <th>tags_idm</th>\n",
       "      <th>tags_indie</th>\n",
       "      <th>tags_indierock</th>\n",
       "      <th>tags_london</th>\n",
       "      <th>tags_losangeles</th>\n",
       "      <th>tags_melbourne</th>\n",
       "      <th>tags_metal</th>\n",
       "      <th>tags_newyork</th>\n",
       "      <th>tags_other</th>\n",
       "      <th>tags_paris</th>\n",
       "      <th>tags_poppunk</th>\n",
       "      <th>tags_progressiverock</th>\n",
       "      <th>tags_punk</th>\n",
       "      <th>tags_rb</th>\n",
       "      <th>tags_rb/soul</th>\n",
       "      <th>tags_rock</th>\n",
       "      <th>tags_spokenword</th>\n",
       "      <th>tags_techno</th>\n",
       "      <th>tags_unitedkingdom</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_price  numTracks  albumRelease  BC_friday  item_type_a  item_type_t  \\\n",
       "0        5.00        4.0             1          0            1            0   \n",
       "1        1.75        1.0             1          0            0            1   \n",
       "2        0.00        1.0             2          0            1            0   \n",
       "3        2.25        1.0             1          0            0            1   \n",
       "4        0.00       10.0             1          0            1            0   \n",
       "\n",
       "   country_code_ad  country_code_ae  country_code_am  country_code_ar  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_at  country_code_au  country_code_aw  country_code_az  \\\n",
       "0                0                0                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ba  country_code_bb  country_code_be  country_code_bg  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_bh  country_code_bm  country_code_bn  country_code_bo  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_br  country_code_bs  country_code_bw  country_code_by  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_c2  country_code_ca  country_code_ch  country_code_cl  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_cn  country_code_co  country_code_cr  country_code_cy  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_cz  country_code_de  country_code_dk  country_code_do  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_dz  country_code_ec  country_code_ee  country_code_eg  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_es  country_code_fi  country_code_fr  country_code_gb  \\\n",
       "0                0                0                0                1   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ge  country_code_gf  country_code_gg  country_code_gi  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_gl  country_code_gp  country_code_gr  country_code_gt  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_gu  country_code_hk  country_code_hn  country_code_hr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_hu  country_code_id  country_code_ie  country_code_il  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_im  country_code_in  country_code_is  country_code_it  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_je  country_code_jm  country_code_jo  country_code_jp  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                1   \n",
       "\n",
       "   country_code_ke  country_code_kg  country_code_kh  country_code_kr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_kw  country_code_kz  country_code_lb  country_code_li  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_lk  country_code_lt  country_code_lu  country_code_lv  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ma  country_code_md  country_code_me  country_code_mk  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_mo  country_code_mq  country_code_mt  country_code_mu  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_mx  country_code_my  country_code_na  country_code_nc  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ni  country_code_nl  country_code_no  country_code_nz  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                1                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_om  country_code_pa  country_code_pe  country_code_pf  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ph  country_code_pk  country_code_pl  country_code_pr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                1                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ps  country_code_pt  country_code_py  country_code_qa  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_re  country_code_ro  country_code_rs  country_code_ru  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_sa  country_code_se  country_code_sg  country_code_si  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_sk  country_code_sn  country_code_sv  country_code_th  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_tn  country_code_tr  country_code_tt  country_code_tw  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ua  country_code_ug  country_code_us  country_code_uy  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ve  country_code_vn  country_code_xk  country_code_za  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   currency_AUD  currency_CAD  currency_CHF  currency_CZK  currency_DKK  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_EUR  currency_GBP  currency_HKD  currency_HUF  currency_ILS  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             1             0             0             0             0   \n",
       "3             1             0             0             0             0   \n",
       "4             0             1             0             0             0   \n",
       "\n",
       "   currency_JPY  currency_MXN  currency_NOK  currency_NZD  currency_PLN  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_SEK  currency_SGD  currency_USD  genre_acoustic  \\\n",
       "0             0             0             1               0   \n",
       "1             0             0             1               0   \n",
       "2             0             0             0               0   \n",
       "3             0             0             0               0   \n",
       "4             0             0             0               0   \n",
       "\n",
       "   genre_alternative  genre_ambient  genre_audiobooks  genre_blues  \\\n",
       "0                  0              0                 0            0   \n",
       "1                  0              0                 0            0   \n",
       "2                  0              0                 0            0   \n",
       "3                  0              0                 0            0   \n",
       "4                  0              1                 0            0   \n",
       "\n",
       "   genre_classical  genre_comedy  genre_country  genre_devotional  \\\n",
       "0                0             0              0                 0   \n",
       "1                0             0              0                 0   \n",
       "2                0             0              0                 0   \n",
       "3                0             0              0                 0   \n",
       "4                0             0              0                 0   \n",
       "\n",
       "   genre_electronic  genre_experimental  genre_folk  genre_funk  \\\n",
       "0                 0                   1           0           0   \n",
       "1                 1                   0           0           0   \n",
       "2                 0                   0           0           0   \n",
       "3                 1                   0           0           0   \n",
       "4                 0                   0           0           0   \n",
       "\n",
       "   genre_hip-hop-rap  genre_jazz  genre_kids  genre_latin  genre_metal  \\\n",
       "0                  0           0           0            0            0   \n",
       "1                  0           0           0            0            0   \n",
       "2                  0           0           0            0            0   \n",
       "3                  0           0           0            0            0   \n",
       "4                  0           0           0            0            0   \n",
       "\n",
       "   genre_other  genre_podcasts  genre_pop  genre_punk  genre_r-b-soul  \\\n",
       "0            0               0          0           0               0   \n",
       "1            0               0          0           0               0   \n",
       "2            0               0          0           0               0   \n",
       "3            0               0          0           0               0   \n",
       "4            0               0          0           0               0   \n",
       "\n",
       "   genre_reggae  genre_rock  genre_soundtrack  genre_spoken-word  genre_world  \\\n",
       "0             0           0                 0                  0            0   \n",
       "1             0           0                 0                  0            0   \n",
       "2             0           0                 0                  0            1   \n",
       "3             0           0                 0                  0            0   \n",
       "4             0           0                 0                  0            0   \n",
       "\n",
       "   inAlbum_in  inAlbum_is  inAlbum_not  tags_140  tags_2step  tags_80s  \\\n",
       "0           0           1            0         0           0         0   \n",
       "1           1           0            0         0           0         0   \n",
       "2           0           1            0         0           0         0   \n",
       "3           1           0            0         0           0         0   \n",
       "4           0           1            0         0           0         0   \n",
       "\n",
       "   tags_acid  tags_acoustic  tags_afrobeat  tags_alternative  \\\n",
       "0          0              0              0                 0   \n",
       "1          0              0              0                 0   \n",
       "2          0              0              0                 0   \n",
       "3          0              0              0                 0   \n",
       "4          0              0              0                 0   \n",
       "\n",
       "   tags_alternativerock  tags_ambientelectronic  tags_americana  \\\n",
       "0                     0                       0               0   \n",
       "1                     0                       0               0   \n",
       "2                     0                       0               0   \n",
       "3                     0                       0               0   \n",
       "4                     0                       0               0   \n",
       "\n",
       "   tags_atmospheric  tags_atmosphericblackmetal  tags_avantgarde  tags_bass  \\\n",
       "0                 0                           0                0          0   \n",
       "1                 0                           0                0          0   \n",
       "2                 0                           0                0          0   \n",
       "3                 0                           0                0          0   \n",
       "4                 0                           0                0          0   \n",
       "\n",
       "   tags_bassmusic  tags_beats  tags_berlin  tags_blackmetal  tags_blues  \\\n",
       "0               0           0            0                0           0   \n",
       "1               0           0            0                0           0   \n",
       "2               0           0            0                0           0   \n",
       "3               0           0            0                0           0   \n",
       "4               0           0            0                0           0   \n",
       "\n",
       "   tags_breakbeat  tags_breaks  tags_brokenbeat  tags_chicago  tags_chillout  \\\n",
       "0               0            0                0             0              0   \n",
       "1               0            0                0             0              0   \n",
       "2               0            0                0             0              0   \n",
       "3               0            0                0             0              0   \n",
       "4               0            0                0             0              0   \n",
       "\n",
       "   tags_chillwave  tags_coldwave  tags_comedy  tags_dance  tags_darkambient  \\\n",
       "0               0              0            0           0                 0   \n",
       "1               0              0            0           0                 0   \n",
       "2               0              0            0           0                 0   \n",
       "3               0              0            0           0                 0   \n",
       "4               0              0            0           0                 0   \n",
       "\n",
       "   tags_darktechno  tags_darkwave  tags_deathmetal  tags_deephouse  \\\n",
       "0                0              0                0               0   \n",
       "1                0              0                0               0   \n",
       "2                0              0                0               0   \n",
       "3                0              0                0               0   \n",
       "4                0              0                0               0   \n",
       "\n",
       "   tags_disco  tags_diy  tags_doom  tags_downtempo  tags_dreampop  tags_drone  \\\n",
       "0           0         0          0               0              0           0   \n",
       "1           0         0          0               0              0           0   \n",
       "2           0         0          0               0              0           0   \n",
       "3           0         0          0               0              0           0   \n",
       "4           0         0          0               0              0           0   \n",
       "\n",
       "   tags_drumbass  tags_dub  tags_dubstep  tags_ebm  tags_edm  tags_electro  \\\n",
       "0              0         0             0         0         0             0   \n",
       "1              0         0             0         0         0             0   \n",
       "2              0         0             0         0         0             0   \n",
       "3              0         0             0         0         0             0   \n",
       "4              0         0             0         0         0             0   \n",
       "\n",
       "   tags_electronic  tags_electronica  tags_experimental  tags_folk  tags_funk  \\\n",
       "0                0                 0                  0          0          0   \n",
       "1                0                 0                  0          0          0   \n",
       "2                0                 0                  0          0          0   \n",
       "3                0                 0                  0          0          0   \n",
       "4                0                 0                  0          0          0   \n",
       "\n",
       "   tags_garage  tags_hardcore  tags_hardrock  tags_hardtechno  tags_hiphop  \\\n",
       "0            0              0              0                0            0   \n",
       "1            0              0              0                0            0   \n",
       "2            0              0              0                0            0   \n",
       "3            0              0              0                0            0   \n",
       "4            0              0              0                0            0   \n",
       "\n",
       "   tags_hiphop/rap  tags_house  tags_idm  tags_indie  tags_indierock  \\\n",
       "0                0           0         0           0               0   \n",
       "1                0           1         0           0               0   \n",
       "2                0           0         0           0               0   \n",
       "3                0           0         0           0               0   \n",
       "4                0           0         0           0               0   \n",
       "\n",
       "   tags_london  tags_losangeles  tags_melbourne  tags_metal  tags_newyork  \\\n",
       "0            0                0               0           0             0   \n",
       "1            0                0               0           0             0   \n",
       "2            0                0               0           0             0   \n",
       "3            0                0               0           0             0   \n",
       "4            0                0               0           0             0   \n",
       "\n",
       "   tags_other  tags_paris  tags_poppunk  tags_progressiverock  tags_punk  \\\n",
       "0           1           0             0                     0          0   \n",
       "1           0           0             0                     0          0   \n",
       "2           1           0             0                     0          0   \n",
       "3           0           0             0                     0          0   \n",
       "4           1           0             0                     0          0   \n",
       "\n",
       "   tags_rb  tags_rb/soul  tags_rock  tags_spokenword  tags_techno  \\\n",
       "0        0             0          0                0            0   \n",
       "1        0             0          0                0            0   \n",
       "2        0             0          0                0            0   \n",
       "3        0             0          0                0            1   \n",
       "4        0             0          0                0            0   \n",
       "\n",
       "   tags_unitedkingdom  day_0  day_1  day_2  day_3  day_4  day_5  day_6  \n",
       "0                   0      0      0      0      0      0      1      0  \n",
       "1                   0      0      0      1      0      0      0      0  \n",
       "2                   0      0      1      0      0      0      0      0  \n",
       "3                   0      0      0      0      1      0      0      0  \n",
       "4                   0      0      1      0      0      0      0      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('X_test.csv', index_col = 0)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "X_test = X_test.drop(['index', 'item_type', 'country_code', 'currency', 'inAlbum', 'genre', 'tags', 'day',\n",
    "                       'coded_country_code', 'coded_currency', 'coded_genre', 'coded_tags'], axis = 1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7190bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize numerical columns: (value - mean) / std\n",
    "dfs = [X_train, X_valid, X_test]\n",
    "num_cols = ['item_price', 'numTracks', 'albumRelease']\n",
    "\n",
    "for data in dfs:\n",
    "    for x in num_cols:\n",
    "        data[x] = (data[x] - np.mean(data[x])) / np.std(data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15472324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_price</th>\n",
       "      <th>numTracks</th>\n",
       "      <th>albumRelease</th>\n",
       "      <th>BC_friday</th>\n",
       "      <th>item_type_a</th>\n",
       "      <th>item_type_t</th>\n",
       "      <th>country_code_ad</th>\n",
       "      <th>country_code_ae</th>\n",
       "      <th>country_code_am</th>\n",
       "      <th>country_code_ar</th>\n",
       "      <th>country_code_at</th>\n",
       "      <th>country_code_au</th>\n",
       "      <th>country_code_aw</th>\n",
       "      <th>country_code_az</th>\n",
       "      <th>country_code_ba</th>\n",
       "      <th>country_code_bb</th>\n",
       "      <th>country_code_be</th>\n",
       "      <th>country_code_bg</th>\n",
       "      <th>country_code_bh</th>\n",
       "      <th>country_code_bm</th>\n",
       "      <th>country_code_bn</th>\n",
       "      <th>country_code_bo</th>\n",
       "      <th>country_code_br</th>\n",
       "      <th>country_code_bs</th>\n",
       "      <th>country_code_bw</th>\n",
       "      <th>country_code_by</th>\n",
       "      <th>country_code_c2</th>\n",
       "      <th>country_code_ca</th>\n",
       "      <th>country_code_ch</th>\n",
       "      <th>country_code_cl</th>\n",
       "      <th>country_code_cn</th>\n",
       "      <th>country_code_co</th>\n",
       "      <th>country_code_cr</th>\n",
       "      <th>country_code_cy</th>\n",
       "      <th>country_code_cz</th>\n",
       "      <th>country_code_de</th>\n",
       "      <th>country_code_dk</th>\n",
       "      <th>country_code_do</th>\n",
       "      <th>country_code_dz</th>\n",
       "      <th>country_code_ec</th>\n",
       "      <th>country_code_ee</th>\n",
       "      <th>country_code_eg</th>\n",
       "      <th>country_code_es</th>\n",
       "      <th>country_code_fi</th>\n",
       "      <th>country_code_fr</th>\n",
       "      <th>country_code_gb</th>\n",
       "      <th>country_code_ge</th>\n",
       "      <th>country_code_gf</th>\n",
       "      <th>country_code_gg</th>\n",
       "      <th>country_code_gi</th>\n",
       "      <th>country_code_gl</th>\n",
       "      <th>country_code_gp</th>\n",
       "      <th>country_code_gr</th>\n",
       "      <th>country_code_gt</th>\n",
       "      <th>country_code_gu</th>\n",
       "      <th>country_code_hk</th>\n",
       "      <th>country_code_hn</th>\n",
       "      <th>country_code_hr</th>\n",
       "      <th>country_code_hu</th>\n",
       "      <th>country_code_id</th>\n",
       "      <th>country_code_ie</th>\n",
       "      <th>country_code_il</th>\n",
       "      <th>country_code_im</th>\n",
       "      <th>country_code_in</th>\n",
       "      <th>country_code_is</th>\n",
       "      <th>country_code_it</th>\n",
       "      <th>country_code_je</th>\n",
       "      <th>country_code_jm</th>\n",
       "      <th>country_code_jo</th>\n",
       "      <th>country_code_jp</th>\n",
       "      <th>country_code_ke</th>\n",
       "      <th>country_code_kg</th>\n",
       "      <th>country_code_kh</th>\n",
       "      <th>country_code_kr</th>\n",
       "      <th>country_code_kw</th>\n",
       "      <th>country_code_kz</th>\n",
       "      <th>country_code_lb</th>\n",
       "      <th>country_code_li</th>\n",
       "      <th>country_code_lk</th>\n",
       "      <th>country_code_lt</th>\n",
       "      <th>country_code_lu</th>\n",
       "      <th>country_code_lv</th>\n",
       "      <th>country_code_ma</th>\n",
       "      <th>country_code_md</th>\n",
       "      <th>country_code_me</th>\n",
       "      <th>country_code_mk</th>\n",
       "      <th>country_code_mo</th>\n",
       "      <th>country_code_mq</th>\n",
       "      <th>country_code_mt</th>\n",
       "      <th>country_code_mu</th>\n",
       "      <th>country_code_mx</th>\n",
       "      <th>country_code_my</th>\n",
       "      <th>country_code_na</th>\n",
       "      <th>country_code_nc</th>\n",
       "      <th>country_code_ni</th>\n",
       "      <th>country_code_nl</th>\n",
       "      <th>country_code_no</th>\n",
       "      <th>country_code_nz</th>\n",
       "      <th>country_code_om</th>\n",
       "      <th>country_code_pa</th>\n",
       "      <th>country_code_pe</th>\n",
       "      <th>country_code_pf</th>\n",
       "      <th>country_code_ph</th>\n",
       "      <th>country_code_pk</th>\n",
       "      <th>country_code_pl</th>\n",
       "      <th>country_code_pr</th>\n",
       "      <th>country_code_ps</th>\n",
       "      <th>country_code_pt</th>\n",
       "      <th>country_code_py</th>\n",
       "      <th>country_code_qa</th>\n",
       "      <th>country_code_re</th>\n",
       "      <th>country_code_ro</th>\n",
       "      <th>country_code_rs</th>\n",
       "      <th>country_code_ru</th>\n",
       "      <th>country_code_sa</th>\n",
       "      <th>country_code_se</th>\n",
       "      <th>country_code_sg</th>\n",
       "      <th>country_code_si</th>\n",
       "      <th>country_code_sk</th>\n",
       "      <th>country_code_sn</th>\n",
       "      <th>country_code_sv</th>\n",
       "      <th>country_code_th</th>\n",
       "      <th>country_code_tn</th>\n",
       "      <th>country_code_tr</th>\n",
       "      <th>country_code_tt</th>\n",
       "      <th>country_code_tw</th>\n",
       "      <th>country_code_ua</th>\n",
       "      <th>country_code_ug</th>\n",
       "      <th>country_code_us</th>\n",
       "      <th>country_code_uy</th>\n",
       "      <th>country_code_ve</th>\n",
       "      <th>country_code_vn</th>\n",
       "      <th>country_code_xk</th>\n",
       "      <th>country_code_za</th>\n",
       "      <th>currency_AUD</th>\n",
       "      <th>currency_CAD</th>\n",
       "      <th>currency_CHF</th>\n",
       "      <th>currency_CZK</th>\n",
       "      <th>currency_DKK</th>\n",
       "      <th>currency_EUR</th>\n",
       "      <th>currency_GBP</th>\n",
       "      <th>currency_HKD</th>\n",
       "      <th>currency_HUF</th>\n",
       "      <th>currency_ILS</th>\n",
       "      <th>currency_JPY</th>\n",
       "      <th>currency_MXN</th>\n",
       "      <th>currency_NOK</th>\n",
       "      <th>currency_NZD</th>\n",
       "      <th>currency_PLN</th>\n",
       "      <th>currency_SEK</th>\n",
       "      <th>currency_SGD</th>\n",
       "      <th>currency_USD</th>\n",
       "      <th>genre_acoustic</th>\n",
       "      <th>genre_alternative</th>\n",
       "      <th>genre_ambient</th>\n",
       "      <th>genre_audiobooks</th>\n",
       "      <th>genre_blues</th>\n",
       "      <th>genre_classical</th>\n",
       "      <th>genre_comedy</th>\n",
       "      <th>genre_country</th>\n",
       "      <th>genre_devotional</th>\n",
       "      <th>genre_electronic</th>\n",
       "      <th>genre_experimental</th>\n",
       "      <th>genre_folk</th>\n",
       "      <th>genre_funk</th>\n",
       "      <th>genre_hip-hop-rap</th>\n",
       "      <th>genre_jazz</th>\n",
       "      <th>genre_kids</th>\n",
       "      <th>genre_latin</th>\n",
       "      <th>genre_metal</th>\n",
       "      <th>genre_other</th>\n",
       "      <th>genre_podcasts</th>\n",
       "      <th>genre_pop</th>\n",
       "      <th>genre_punk</th>\n",
       "      <th>genre_r-b-soul</th>\n",
       "      <th>genre_reggae</th>\n",
       "      <th>genre_rock</th>\n",
       "      <th>genre_soundtrack</th>\n",
       "      <th>genre_spoken-word</th>\n",
       "      <th>genre_world</th>\n",
       "      <th>inAlbum_in</th>\n",
       "      <th>inAlbum_is</th>\n",
       "      <th>inAlbum_not</th>\n",
       "      <th>tags_140</th>\n",
       "      <th>tags_2step</th>\n",
       "      <th>tags_80s</th>\n",
       "      <th>tags_acid</th>\n",
       "      <th>tags_acoustic</th>\n",
       "      <th>tags_afrobeat</th>\n",
       "      <th>tags_alternative</th>\n",
       "      <th>tags_alternativerock</th>\n",
       "      <th>tags_ambientelectronic</th>\n",
       "      <th>tags_americana</th>\n",
       "      <th>tags_atmospheric</th>\n",
       "      <th>tags_atmosphericblackmetal</th>\n",
       "      <th>tags_avantgarde</th>\n",
       "      <th>tags_bass</th>\n",
       "      <th>tags_bassmusic</th>\n",
       "      <th>tags_beats</th>\n",
       "      <th>tags_berlin</th>\n",
       "      <th>tags_blackmetal</th>\n",
       "      <th>tags_blues</th>\n",
       "      <th>tags_breakbeat</th>\n",
       "      <th>tags_breaks</th>\n",
       "      <th>tags_brokenbeat</th>\n",
       "      <th>tags_chicago</th>\n",
       "      <th>tags_chillout</th>\n",
       "      <th>tags_chillwave</th>\n",
       "      <th>tags_coldwave</th>\n",
       "      <th>tags_comedy</th>\n",
       "      <th>tags_dance</th>\n",
       "      <th>tags_darkambient</th>\n",
       "      <th>tags_darktechno</th>\n",
       "      <th>tags_darkwave</th>\n",
       "      <th>tags_deathmetal</th>\n",
       "      <th>tags_deephouse</th>\n",
       "      <th>tags_disco</th>\n",
       "      <th>tags_diy</th>\n",
       "      <th>tags_doom</th>\n",
       "      <th>tags_downtempo</th>\n",
       "      <th>tags_dreampop</th>\n",
       "      <th>tags_drone</th>\n",
       "      <th>tags_drumbass</th>\n",
       "      <th>tags_dub</th>\n",
       "      <th>tags_dubstep</th>\n",
       "      <th>tags_ebm</th>\n",
       "      <th>tags_edm</th>\n",
       "      <th>tags_electro</th>\n",
       "      <th>tags_electronic</th>\n",
       "      <th>tags_electronica</th>\n",
       "      <th>tags_experimental</th>\n",
       "      <th>tags_folk</th>\n",
       "      <th>tags_funk</th>\n",
       "      <th>tags_garage</th>\n",
       "      <th>tags_hardcore</th>\n",
       "      <th>tags_hardrock</th>\n",
       "      <th>tags_hardtechno</th>\n",
       "      <th>tags_hiphop</th>\n",
       "      <th>tags_hiphop/rap</th>\n",
       "      <th>tags_house</th>\n",
       "      <th>tags_idm</th>\n",
       "      <th>tags_indie</th>\n",
       "      <th>tags_indierock</th>\n",
       "      <th>tags_london</th>\n",
       "      <th>tags_losangeles</th>\n",
       "      <th>tags_melbourne</th>\n",
       "      <th>tags_metal</th>\n",
       "      <th>tags_newyork</th>\n",
       "      <th>tags_other</th>\n",
       "      <th>tags_paris</th>\n",
       "      <th>tags_poppunk</th>\n",
       "      <th>tags_progressiverock</th>\n",
       "      <th>tags_punk</th>\n",
       "      <th>tags_rb</th>\n",
       "      <th>tags_rb/soul</th>\n",
       "      <th>tags_rock</th>\n",
       "      <th>tags_spokenword</th>\n",
       "      <th>tags_techno</th>\n",
       "      <th>tags_unitedkingdom</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131991</td>\n",
       "      <td>0.279057</td>\n",
       "      <td>-0.379239</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.720753</td>\n",
       "      <td>-0.568203</td>\n",
       "      <td>-0.379239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.278589</td>\n",
       "      <td>-0.568203</td>\n",
       "      <td>-0.379239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693199</td>\n",
       "      <td>0.173149</td>\n",
       "      <td>-0.379239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.764484</td>\n",
       "      <td>-0.568203</td>\n",
       "      <td>-0.379239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_price  numTracks  albumRelease  BC_friday  item_type_a  item_type_t  \\\n",
       "0    0.131991   0.279057     -0.379239          1            1            0   \n",
       "1   -0.720753  -0.568203     -0.379239          0            0            1   \n",
       "2   -0.278589  -0.568203     -0.379239          0            0            1   \n",
       "3    0.693199   0.173149     -0.379239          0            1            0   \n",
       "4   -0.764484  -0.568203     -0.379239          0            0            1   \n",
       "\n",
       "   country_code_ad  country_code_ae  country_code_am  country_code_ar  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_at  country_code_au  country_code_aw  country_code_az  \\\n",
       "0                0                0                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ba  country_code_bb  country_code_be  country_code_bg  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_bh  country_code_bm  country_code_bn  country_code_bo  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_br  country_code_bs  country_code_bw  country_code_by  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_c2  country_code_ca  country_code_ch  country_code_cl  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_cn  country_code_co  country_code_cr  country_code_cy  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_cz  country_code_de  country_code_dk  country_code_do  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_dz  country_code_ec  country_code_ee  country_code_eg  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_es  country_code_fi  country_code_fr  country_code_gb  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                1   \n",
       "\n",
       "   country_code_ge  country_code_gf  country_code_gg  country_code_gi  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_gl  country_code_gp  country_code_gr  country_code_gt  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_gu  country_code_hk  country_code_hn  country_code_hr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_hu  country_code_id  country_code_ie  country_code_il  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_im  country_code_in  country_code_is  country_code_it  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_je  country_code_jm  country_code_jo  country_code_jp  \\\n",
       "0                0                0                0                1   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ke  country_code_kg  country_code_kh  country_code_kr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_kw  country_code_kz  country_code_lb  country_code_li  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_lk  country_code_lt  country_code_lu  country_code_lv  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ma  country_code_md  country_code_me  country_code_mk  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_mo  country_code_mq  country_code_mt  country_code_mu  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_mx  country_code_my  country_code_na  country_code_nc  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ni  country_code_nl  country_code_no  country_code_nz  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_om  country_code_pa  country_code_pe  country_code_pf  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ph  country_code_pk  country_code_pl  country_code_pr  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ps  country_code_pt  country_code_py  country_code_qa  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_re  country_code_ro  country_code_rs  country_code_ru  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_sa  country_code_se  country_code_sg  country_code_si  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_sk  country_code_sn  country_code_sv  country_code_th  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_tn  country_code_tr  country_code_tt  country_code_tw  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ua  country_code_ug  country_code_us  country_code_uy  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                1                0   \n",
       "3                0                0                1                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   country_code_ve  country_code_vn  country_code_xk  country_code_za  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   currency_AUD  currency_CAD  currency_CHF  currency_CZK  currency_DKK  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_EUR  currency_GBP  currency_HKD  currency_HUF  currency_ILS  \\\n",
       "0             1             0             0             0             0   \n",
       "1             1             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_JPY  currency_MXN  currency_NOK  currency_NZD  currency_PLN  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   currency_SEK  currency_SGD  currency_USD  genre_acoustic  \\\n",
       "0             0             0             0               0   \n",
       "1             0             0             0               0   \n",
       "2             0             0             1               0   \n",
       "3             0             0             1               0   \n",
       "4             0             0             1               0   \n",
       "\n",
       "   genre_alternative  genre_ambient  genre_audiobooks  genre_blues  \\\n",
       "0                  0              0                 0            0   \n",
       "1                  0              0                 0            0   \n",
       "2                  0              0                 0            0   \n",
       "3                  1              0                 0            0   \n",
       "4                  1              0                 0            0   \n",
       "\n",
       "   genre_classical  genre_comedy  genre_country  genre_devotional  \\\n",
       "0                0             0              0                 0   \n",
       "1                0             0              0                 0   \n",
       "2                0             0              0                 0   \n",
       "3                0             0              0                 0   \n",
       "4                0             0              0                 0   \n",
       "\n",
       "   genre_electronic  genre_experimental  genre_folk  genre_funk  \\\n",
       "0                 0                   1           0           0   \n",
       "1                 1                   0           0           0   \n",
       "2                 1                   0           0           0   \n",
       "3                 0                   0           0           0   \n",
       "4                 0                   0           0           0   \n",
       "\n",
       "   genre_hip-hop-rap  genre_jazz  genre_kids  genre_latin  genre_metal  \\\n",
       "0                  0           0           0            0            0   \n",
       "1                  0           0           0            0            0   \n",
       "2                  0           0           0            0            0   \n",
       "3                  0           0           0            0            0   \n",
       "4                  0           0           0            0            0   \n",
       "\n",
       "   genre_other  genre_podcasts  genre_pop  genre_punk  genre_r-b-soul  \\\n",
       "0            0               0          0           0               0   \n",
       "1            0               0          0           0               0   \n",
       "2            0               0          0           0               0   \n",
       "3            0               0          0           0               0   \n",
       "4            0               0          0           0               0   \n",
       "\n",
       "   genre_reggae  genre_rock  genre_soundtrack  genre_spoken-word  genre_world  \\\n",
       "0             0           0                 0                  0            0   \n",
       "1             0           0                 0                  0            0   \n",
       "2             0           0                 0                  0            0   \n",
       "3             0           0                 0                  0            0   \n",
       "4             0           0                 0                  0            0   \n",
       "\n",
       "   inAlbum_in  inAlbum_is  inAlbum_not  tags_140  tags_2step  tags_80s  \\\n",
       "0           0           1            0         0           0         0   \n",
       "1           1           0            0         0           0         0   \n",
       "2           0           0            1         0           0         0   \n",
       "3           0           1            0         0           0         0   \n",
       "4           1           0            0         0           0         0   \n",
       "\n",
       "   tags_acid  tags_acoustic  tags_afrobeat  tags_alternative  \\\n",
       "0          0              0              0                 0   \n",
       "1          1              0              0                 0   \n",
       "2          0              0              0                 0   \n",
       "3          0              0              0                 0   \n",
       "4          0              0              0                 0   \n",
       "\n",
       "   tags_alternativerock  tags_ambientelectronic  tags_americana  \\\n",
       "0                     0                       0               0   \n",
       "1                     0                       0               0   \n",
       "2                     0                       0               0   \n",
       "3                     0                       0               0   \n",
       "4                     0                       0               0   \n",
       "\n",
       "   tags_atmospheric  tags_atmosphericblackmetal  tags_avantgarde  tags_bass  \\\n",
       "0                 0                           0                0          0   \n",
       "1                 0                           0                0          0   \n",
       "2                 0                           0                0          0   \n",
       "3                 0                           0                0          0   \n",
       "4                 0                           0                0          0   \n",
       "\n",
       "   tags_bassmusic  tags_beats  tags_berlin  tags_blackmetal  tags_blues  \\\n",
       "0               0           0            0                0           0   \n",
       "1               0           0            0                0           0   \n",
       "2               0           0            0                0           0   \n",
       "3               0           0            0                0           0   \n",
       "4               0           0            0                0           0   \n",
       "\n",
       "   tags_breakbeat  tags_breaks  tags_brokenbeat  tags_chicago  tags_chillout  \\\n",
       "0               0            0                0             0              0   \n",
       "1               0            0                0             0              0   \n",
       "2               0            0                0             0              0   \n",
       "3               0            0                0             0              0   \n",
       "4               0            0                0             0              0   \n",
       "\n",
       "   tags_chillwave  tags_coldwave  tags_comedy  tags_dance  tags_darkambient  \\\n",
       "0               0              0            0           0                 0   \n",
       "1               0              0            0           0                 0   \n",
       "2               0              0            0           0                 0   \n",
       "3               0              0            0           0                 0   \n",
       "4               0              0            0           0                 0   \n",
       "\n",
       "   tags_darktechno  tags_darkwave  tags_deathmetal  tags_deephouse  \\\n",
       "0                0              0                0               0   \n",
       "1                0              0                0               0   \n",
       "2                0              0                0               0   \n",
       "3                0              0                0               0   \n",
       "4                0              0                0               0   \n",
       "\n",
       "   tags_disco  tags_diy  tags_doom  tags_downtempo  tags_dreampop  tags_drone  \\\n",
       "0           0         0          0               0              0           0   \n",
       "1           0         0          0               0              0           0   \n",
       "2           0         0          0               0              0           0   \n",
       "3           0         0          0               0              0           0   \n",
       "4           0         0          0               0              0           0   \n",
       "\n",
       "   tags_drumbass  tags_dub  tags_dubstep  tags_ebm  tags_edm  tags_electro  \\\n",
       "0              0         0             0         0         0             0   \n",
       "1              0         0             0         0         0             0   \n",
       "2              0         0             0         0         0             0   \n",
       "3              0         0             0         0         0             0   \n",
       "4              0         0             0         0         0             0   \n",
       "\n",
       "   tags_electronic  tags_electronica  tags_experimental  tags_folk  tags_funk  \\\n",
       "0                1                 0                  0          0          0   \n",
       "1                0                 0                  0          0          0   \n",
       "2                0                 0                  0          0          0   \n",
       "3                0                 0                  0          0          0   \n",
       "4                1                 0                  0          0          0   \n",
       "\n",
       "   tags_garage  tags_hardcore  tags_hardrock  tags_hardtechno  tags_hiphop  \\\n",
       "0            0              0              0                0            0   \n",
       "1            0              0              0                0            0   \n",
       "2            0              0              0                0            0   \n",
       "3            0              0              0                0            0   \n",
       "4            0              0              0                0            0   \n",
       "\n",
       "   tags_hiphop/rap  tags_house  tags_idm  tags_indie  tags_indierock  \\\n",
       "0                0           0         0           0               0   \n",
       "1                0           0         0           0               0   \n",
       "2                0           0         0           0               0   \n",
       "3                0           0         0           0               0   \n",
       "4                0           0         0           0               0   \n",
       "\n",
       "   tags_london  tags_losangeles  tags_melbourne  tags_metal  tags_newyork  \\\n",
       "0            0                0               0           0             0   \n",
       "1            0                0               0           0             0   \n",
       "2            0                0               0           0             0   \n",
       "3            0                0               0           0             0   \n",
       "4            0                0               0           0             0   \n",
       "\n",
       "   tags_other  tags_paris  tags_poppunk  tags_progressiverock  tags_punk  \\\n",
       "0           0           0             0                     0          0   \n",
       "1           0           0             0                     0          0   \n",
       "2           1           0             0                     0          0   \n",
       "3           1           0             0                     0          0   \n",
       "4           0           0             0                     0          0   \n",
       "\n",
       "   tags_rb  tags_rb/soul  tags_rock  tags_spokenword  tags_techno  \\\n",
       "0        0             0          0                0            0   \n",
       "1        0             0          0                0            0   \n",
       "2        0             0          0                0            0   \n",
       "3        0             0          0                0            0   \n",
       "4        0             0          0                0            0   \n",
       "\n",
       "   tags_unitedkingdom  day_0  day_1  day_2  day_3  day_4  day_5  day_6  \n",
       "0                   0      0      0      0      0      0      1      0  \n",
       "1                   0      0      0      1      0      0      0      0  \n",
       "2                   0      0      0      1      0      0      0      0  \n",
       "3                   0      0      0      0      0      1      0      0  \n",
       "4                   0      0      0      0      0      1      0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86ff343",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('y_train.csv', index_col = 0)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "\n",
    "y_train = y_train['amount_paid_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c760f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.read_csv('y_valid.csv', index_col = 0)\n",
    "y_valid = y_valid.reset_index(drop = True)\n",
    "\n",
    "y_valid = y_valid['amount_paid_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23db319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('y_test.csv', index_col = 0)\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "\n",
    "y_test = y_test['amount_paid_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb704d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398130, 398130, 132710, 132710, 132711, 132711)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_valid), len(y_valid), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a602e0db",
   "metadata": {},
   "source": [
    "#y_dfs = [y_train, y_valid, y_test]\n",
    "\n",
    "#for data in y_dfs:\n",
    "    #data['amount_paid_usd'] = (data['amount_paid_usd'] - np.mean(data['amount_paid_usd'])) / np.std(data['amount_paid_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a8d03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2de15",
   "metadata": {},
   "source": [
    "### Optimizer & batch-size selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "623990f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(o):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim = X_train.shape[1], activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation = 'linear'))\n",
    "    model.compile(loss = 'mse', optimizer = o)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370c04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [25, 50, 75, 100, 150, 200]\n",
    "optimizers = ['adam', 'RMSprop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05de866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(batch, optimizer):\n",
    "    es = EarlyStopping(monitor = 'val_loss', mode='min', patience = 5, restore_best_weights = True)\n",
    "    nn_mod = nn_model(o)\n",
    "    print(nn_mod.summary())\n",
    "    nn_mod.fit(X_train, y_train, batch_size = b, epochs = 100, validation_data = (X_valid, y_valid), callbacks=[es])\n",
    "    pred = nn_mod.predict(X_valid)\n",
    "    print('RMSE on valid data:', sqrt(mse(y_valid, pred)))\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39325daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "15926/15926 [==============================] - 18s 1ms/step - loss: 18.4554 - val_loss: 14.3769\n",
      "Epoch 2/100\n",
      "15926/15926 [==============================] - 17s 1ms/step - loss: 17.4232 - val_loss: 14.3566\n",
      "Epoch 3/100\n",
      "15926/15926 [==============================] - 17s 1ms/step - loss: 17.2200 - val_loss: 14.5946\n",
      "Epoch 4/100\n",
      "15926/15926 [==============================] - 18s 1ms/step - loss: 17.0709 - val_loss: 14.6866\n",
      "Epoch 5/100\n",
      "15926/15926 [==============================] - 17s 1ms/step - loss: 17.0202 - val_loss: 17.3227\n",
      "Epoch 6/100\n",
      "15926/15926 [==============================] - 17s 1ms/step - loss: 16.9861 - val_loss: 19.5600\n",
      "Epoch 7/100\n",
      "15926/15926 [==============================] - 17s 1ms/step - loss: 16.9144 - val_loss: 20.7922\n",
      "4148/4148 [==============================] - 2s 530us/step\n",
      "RMSE on valid data: 3.7890183460182874\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "15926/15926 [==============================] - 17s 1ms/step - loss: 18.3247 - val_loss: 14.7282\n",
      "Epoch 2/100\n",
      "15926/15926 [==============================] - 16s 993us/step - loss: 17.4942 - val_loss: 14.7584\n",
      "Epoch 3/100\n",
      "15926/15926 [==============================] - 16s 995us/step - loss: 17.3945 - val_loss: 14.0210\n",
      "Epoch 4/100\n",
      "15926/15926 [==============================] - 16s 1ms/step - loss: 17.3695 - val_loss: 14.1499\n",
      "Epoch 5/100\n",
      "15926/15926 [==============================] - 17s 1ms/step - loss: 17.3483 - val_loss: 14.7677\n",
      "Epoch 6/100\n",
      "15926/15926 [==============================] - 16s 999us/step - loss: 17.3031 - val_loss: 15.1350\n",
      "Epoch 7/100\n",
      "15926/15926 [==============================] - 16s 1ms/step - loss: 17.3080 - val_loss: 13.9734\n",
      "Epoch 8/100\n",
      "15926/15926 [==============================] - 16s 999us/step - loss: 17.2727 - val_loss: 14.0190\n",
      "Epoch 9/100\n",
      "15926/15926 [==============================] - 16s 996us/step - loss: 17.2932 - val_loss: 14.0083\n",
      "Epoch 10/100\n",
      "15926/15926 [==============================] - 16s 998us/step - loss: 17.2741 - val_loss: 14.1121\n",
      "Epoch 11/100\n",
      "15926/15926 [==============================] - 16s 1ms/step - loss: 17.2365 - val_loss: 15.1374\n",
      "Epoch 12/100\n",
      "15926/15926 [==============================] - 16s 1ms/step - loss: 17.2737 - val_loss: 15.4088\n",
      "4148/4148 [==============================] - 2s 526us/step\n",
      "RMSE on valid data: 3.738103774929067\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "7963/7963 [==============================] - 10s 1ms/step - loss: 18.4232 - val_loss: 13.8311\n",
      "Epoch 2/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 17.0684 - val_loss: 13.7986\n",
      "Epoch 3/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.8123 - val_loss: 13.7820\n",
      "Epoch 4/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.7040 - val_loss: 13.7939\n",
      "Epoch 5/100\n",
      "7963/7963 [==============================] - 10s 1ms/step - loss: 16.6073 - val_loss: 13.6647\n",
      "Epoch 6/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.5463 - val_loss: 13.8756\n",
      "Epoch 7/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.4745 - val_loss: 13.8117\n",
      "Epoch 8/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.4532 - val_loss: 13.7439\n",
      "Epoch 9/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.3967 - val_loss: 15.9697\n",
      "Epoch 10/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.3764 - val_loss: 14.4315\n",
      "4148/4148 [==============================] - 2s 537us/step\n",
      "RMSE on valid data: 3.6965783884842893\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "7963/7963 [==============================] - 10s 1ms/step - loss: 18.3339 - val_loss: 14.2460\n",
      "Epoch 2/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 17.0925 - val_loss: 14.6547\n",
      "Epoch 3/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.9349 - val_loss: 14.1810\n",
      "Epoch 4/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.8634 - val_loss: 14.0748\n",
      "Epoch 5/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.8192 - val_loss: 14.1955\n",
      "Epoch 6/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.7865 - val_loss: 16.6655\n",
      "Epoch 7/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.7852 - val_loss: 30.5443\n",
      "Epoch 8/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.6819 - val_loss: 32.4025\n",
      "Epoch 9/100\n",
      "7963/7963 [==============================] - 9s 1ms/step - loss: 16.6732 - val_loss: 359.3692\n",
      "4148/4148 [==============================] - 2s 570us/step\n",
      "RMSE on valid data: 3.7516358096355797\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5309/5309 [==============================] - 10s 2ms/step - loss: 18.6054 - val_loss: 13.8694\n",
      "Epoch 2/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.8318 - val_loss: 13.6952\n",
      "Epoch 3/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.6807 - val_loss: 13.6520\n",
      "Epoch 4/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.5410 - val_loss: 13.6607\n",
      "Epoch 5/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.4824 - val_loss: 13.6775\n",
      "Epoch 6/100\n",
      "5309/5309 [==============================] - 8s 1ms/step - loss: 16.4053 - val_loss: 13.6556\n",
      "Epoch 7/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.3283 - val_loss: 13.7051\n",
      "Epoch 8/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.2892 - val_loss: 14.0054\n",
      "4148/4148 [==============================] - 2s 503us/step\n",
      "RMSE on valid data: 3.69486411295704\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5309/5309 [==============================] - 8s 1ms/step - loss: 18.5733 - val_loss: 13.9804\n",
      "Epoch 2/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.9560 - val_loss: 13.9672\n",
      "Epoch 3/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.8315 - val_loss: 14.4563\n",
      "Epoch 4/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.7533 - val_loss: 15.6592\n",
      "Epoch 5/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.6919 - val_loss: 19.4846\n",
      "Epoch 6/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.5897 - val_loss: 27.6018\n",
      "Epoch 7/100\n",
      "5309/5309 [==============================] - 7s 1ms/step - loss: 16.5917 - val_loss: 41.5728\n",
      "4148/4148 [==============================] - 2s 545us/step\n",
      "RMSE on valid data: 3.737271685728908\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 18.9739 - val_loss: 13.8021\n",
      "Epoch 2/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.7475 - val_loss: 13.7396\n",
      "Epoch 3/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.6163 - val_loss: 13.6913\n",
      "Epoch 4/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.4687 - val_loss: 13.7274\n",
      "Epoch 5/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.4318 - val_loss: 13.7741\n",
      "Epoch 6/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.3187 - val_loss: 13.6619\n",
      "Epoch 7/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.2786 - val_loss: 13.6800\n",
      "Epoch 8/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.2206 - val_loss: 13.7909\n",
      "Epoch 9/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.1785 - val_loss: 13.7166\n",
      "Epoch 10/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.1447 - val_loss: 14.1261\n",
      "Epoch 11/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.1002 - val_loss: 13.7842\n",
      "4148/4148 [==============================] - 2s 507us/step\n",
      "RMSE on valid data: 3.6962024515449414\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 18.7512 - val_loss: 14.1158\n",
      "Epoch 2/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.7954 - val_loss: 14.0216\n",
      "Epoch 3/100\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.6856 - val_loss: 14.0628\n",
      "Epoch 4/100\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.6035 - val_loss: 14.0301\n",
      "Epoch 5/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.5077 - val_loss: 13.8879\n",
      "Epoch 6/100\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4540 - val_loss: 13.9580\n",
      "Epoch 7/100\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4337 - val_loss: 13.8768\n",
      "Epoch 8/100\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 16.3950 - val_loss: 13.8427\n",
      "Epoch 9/100\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4294 - val_loss: 13.9761\n",
      "Epoch 10/100\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.3610 - val_loss: 13.8490\n",
      "Epoch 11/100\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4054 - val_loss: 13.9532\n",
      "Epoch 12/100\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.3686 - val_loss: 13.9458\n",
      "Epoch 13/100\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.3776 - val_loss: 14.0435\n",
      "4148/4148 [==============================] - 2s 537us/step\n",
      "RMSE on valid data: 3.7205730808631605\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 19.4161 - val_loss: 13.8211\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 4s 1ms/step - loss: 16.6812 - val_loss: 13.7319\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 4s 1ms/step - loss: 16.4606 - val_loss: 13.6577\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.3866 - val_loss: 13.6273\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.2598 - val_loss: 13.5770\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.2055 - val_loss: 13.5880\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.1195 - val_loss: 13.5629\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.1056 - val_loss: 13.5525\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 4s 1ms/step - loss: 16.0342 - val_loss: 13.5316\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 4s 1ms/step - loss: 16.0292 - val_loss: 13.5475\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.9825 - val_loss: 13.5238\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.9643 - val_loss: 13.5503\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 4s 1ms/step - loss: 15.9367 - val_loss: 13.5390\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 4s 1ms/step - loss: 15.9249 - val_loss: 13.5242\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 4s 1ms/step - loss: 15.8793 - val_loss: 13.5572\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.8711 - val_loss: 13.5372\n",
      "4148/4148 [==============================] - 2s 531us/step\n",
      "RMSE on valid data: 3.677464451000117\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 19.4104 - val_loss: 14.0276\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.6682 - val_loss: 14.0642\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.5261 - val_loss: 13.9871\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.4686 - val_loss: 14.1202\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.4113 - val_loss: 14.1473\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.3764 - val_loss: 14.0325\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.3468 - val_loss: 14.0510\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.2885 - val_loss: 13.9583\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.3151 - val_loss: 13.8778\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.2776 - val_loss: 13.9202\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.2432 - val_loss: 13.9378\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.2521 - val_loss: 14.0218\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.2395 - val_loss: 13.9251\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.2132 - val_loss: 13.9708\n",
      "4148/4148 [==============================] - 2s 552us/step\n",
      "RMSE on valid data: 3.725291753699742\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1991/1991 [==============================] - 5s 2ms/step - loss: 20.5535 - val_loss: 13.8357\n",
      "Epoch 2/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 16.5845 - val_loss: 13.7132\n",
      "Epoch 3/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.3948 - val_loss: 13.6759\n",
      "Epoch 4/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.2978 - val_loss: 13.6595\n",
      "Epoch 5/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 16.1633 - val_loss: 13.6472\n",
      "Epoch 6/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 16.1463 - val_loss: 13.6226\n",
      "Epoch 7/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 16.0443 - val_loss: 13.6316\n",
      "Epoch 8/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 15.9959 - val_loss: 13.6982\n",
      "Epoch 9/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 15.9966 - val_loss: 13.7365\n",
      "Epoch 10/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 15.9576 - val_loss: 13.7331\n",
      "Epoch 11/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 15.8807 - val_loss: 13.6857\n",
      "4148/4148 [==============================] - 2s 533us/step\n",
      "RMSE on valid data: 3.6908837696890937\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 20.1665 - val_loss: 13.9641\n",
      "Epoch 2/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.6422 - val_loss: 13.8996\n",
      "Epoch 3/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.5232 - val_loss: 13.9114\n",
      "Epoch 4/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.4173 - val_loss: 13.8809\n",
      "Epoch 5/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.3937 - val_loss: 13.8945\n",
      "Epoch 6/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.3138 - val_loss: 13.8670\n",
      "Epoch 7/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.3007 - val_loss: 13.8718\n",
      "Epoch 8/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.2764 - val_loss: 13.8573\n",
      "Epoch 9/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.2360 - val_loss: 13.9790\n",
      "Epoch 10/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.2504 - val_loss: 13.9528\n",
      "Epoch 11/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.2105 - val_loss: 13.9632\n",
      "Epoch 12/100\n",
      "1991/1991 [==============================] - 4s 2ms/step - loss: 16.1719 - val_loss: 13.8827\n",
      "Epoch 13/100\n",
      "1991/1991 [==============================] - 3s 2ms/step - loss: 16.1840 - val_loss: 13.8586\n",
      "4148/4148 [==============================] - 2s 532us/step\n",
      "RMSE on valid data: 3.722544284240609\n"
     ]
    }
   ],
   "source": [
    "for b in batches:\n",
    "    for o in optimizers:\n",
    "        train_nn(b, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb8798",
   "metadata": {},
   "source": [
    "#### Selected batch size: 150, optimizer = adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba5b43e",
   "metadata": {},
   "source": [
    "### Architecture testing & activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "220cb819",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = ['relu', keras.layers.LeakyReLU(), 'linear']\n",
    "neurons = [32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84cb851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Hidden layer\n",
    "def nn_model1(n,a):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_dim = X_train.shape[1], activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation = 'linear'))\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a2a30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(neurons, activations):\n",
    "    es = EarlyStopping(monitor = 'val_loss', mode='min', patience = 5, restore_best_weights = True)\n",
    "    for n in neurons:\n",
    "        for a in activations:\n",
    "            nn_mod = nn_model1(n,a)\n",
    "            print(nn_mod.summary())\n",
    "            nn_mod.fit(X_train, y_train, batch_size = 100, epochs = 50, validation_data=(X_valid, y_valid), callbacks=[es])\n",
    "            pred = nn_mod.predict(X_valid)\n",
    "            print('RMSE on valid data:', sqrt(mse(y_valid, pred)))\n",
    "            keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d32c813b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 17.8182 - val_loss: 13.9540\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.1628 - val_loss: 14.2804\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0439 - val_loss: 14.1685\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.9664 - val_loss: 13.8596\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.9069 - val_loss: 14.1502\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.8649 - val_loss: 14.9219\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.8518 - val_loss: 14.3373\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.8137 - val_loss: 14.4873\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.7881 - val_loss: 14.2423\n",
      "4148/4148 [==============================] - 2s 510us/step\n",
      "RMSE on valid data: 3.722846397552458\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 17.9668 - val_loss: 13.9243\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.2815 - val_loss: 13.8697\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.1994 - val_loss: 13.8811\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.1485 - val_loss: 13.8835\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0987 - val_loss: 13.8481\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0952 - val_loss: 13.8401\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0686 - val_loss: 13.8144\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0778 - val_loss: 13.8403\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0393 - val_loss: 13.7953\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0499 - val_loss: 13.8022\n",
      "Epoch 11/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0078 - val_loss: 13.8096\n",
      "Epoch 12/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0101 - val_loss: 13.8163\n",
      "Epoch 13/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0153 - val_loss: 13.7821\n",
      "Epoch 14/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.0008 - val_loss: 13.8088\n",
      "Epoch 15/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.9827 - val_loss: 13.7950\n",
      "Epoch 16/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.9949 - val_loss: 13.8222\n",
      "Epoch 17/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.9825 - val_loss: 13.7825\n",
      "Epoch 18/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.9734 - val_loss: 13.7874\n",
      "4148/4148 [==============================] - 2s 490us/step\n",
      "RMSE on valid data: 3.712429023920455\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 18.3526 - val_loss: 14.4167\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.6441 - val_loss: 14.3464\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.6098 - val_loss: 14.3012\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.5480 - val_loss: 14.2977\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.5635 - val_loss: 14.3000\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.5708 - val_loss: 14.2989\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.5316 - val_loss: 14.3204\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.5191 - val_loss: 14.2947\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.5186 - val_loss: 14.2911\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.5142 - val_loss: 14.3033\n",
      "Epoch 11/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4950 - val_loss: 14.3353\n",
      "Epoch 12/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.5075 - val_loss: 14.2968\n",
      "Epoch 13/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4881 - val_loss: 14.2969\n",
      "Epoch 14/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4669 - val_loss: 14.2907\n",
      "Epoch 15/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4817 - val_loss: 14.3069\n",
      "Epoch 16/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4790 - val_loss: 14.2950\n",
      "Epoch 17/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4544 - val_loss: 14.3076\n",
      "Epoch 18/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4650 - val_loss: 14.3070\n",
      "Epoch 19/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 16.4643 - val_loss: 14.2970\n",
      "4148/4148 [==============================] - 2s 517us/step\n",
      "RMSE on valid data: 3.7803030353528944\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,409\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 17.4166 - val_loss: 14.0535\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 15.8597 - val_loss: 14.0890\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 15.7443 - val_loss: 14.1011\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.6551 - val_loss: 14.5796\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 5s 1ms/step - loss: 15.6393 - val_loss: 14.1255\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 6s 1ms/step - loss: 15.5701 - val_loss: 14.3459\n",
      "4148/4148 [==============================] - 2s 484us/step\n",
      "RMSE on valid data: 3.7487992695385084\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,409\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 17.5727 - val_loss: 13.9877\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.0514 - val_loss: 13.8476\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.0051 - val_loss: 13.8625\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.9415 - val_loss: 13.7793\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.9327 - val_loss: 13.7783\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.8836 - val_loss: 13.8086\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.8806 - val_loss: 13.8910\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.8619 - val_loss: 13.7617\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.8476 - val_loss: 13.7251\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.8340 - val_loss: 13.7190\n",
      "Epoch 11/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.8424 - val_loss: 13.7279\n",
      "Epoch 12/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7984 - val_loss: 13.7500\n",
      "Epoch 13/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.8009 - val_loss: 13.7422\n",
      "Epoch 14/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7886 - val_loss: 13.7236\n",
      "Epoch 15/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7968 - val_loss: 13.7107\n",
      "Epoch 16/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7537 - val_loss: 13.7060\n",
      "Epoch 17/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7738 - val_loss: 13.7007\n",
      "Epoch 18/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7848 - val_loss: 13.7079\n",
      "Epoch 19/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7569 - val_loss: 13.7696\n",
      "Epoch 20/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7331 - val_loss: 13.7041\n",
      "Epoch 21/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7704 - val_loss: 13.6951\n",
      "Epoch 22/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7531 - val_loss: 13.7005\n",
      "Epoch 23/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7487 - val_loss: 13.6959\n",
      "Epoch 24/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7199 - val_loss: 13.7208\n",
      "Epoch 25/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7500 - val_loss: 13.7375\n",
      "Epoch 26/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7451 - val_loss: 13.7312\n",
      "4148/4148 [==============================] - 2s 528us/step\n",
      "RMSE on valid data: 3.700684608272397\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,409\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 17.8111 - val_loss: 14.3782\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.4735 - val_loss: 14.3681\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.4304 - val_loss: 14.3540\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.4050 - val_loss: 14.3205\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3926 - val_loss: 14.3182\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3850 - val_loss: 14.3031\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3900 - val_loss: 14.3003\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.4025 - val_loss: 14.2866\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.4090 - val_loss: 14.3406\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3771 - val_loss: 14.2990\n",
      "Epoch 11/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3636 - val_loss: 14.3210\n",
      "Epoch 12/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3875 - val_loss: 14.3259\n",
      "Epoch 13/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3874 - val_loss: 14.2912\n",
      "4148/4148 [==============================] - 2s 527us/step\n",
      "RMSE on valid data: 3.7797567999767057\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,817\n",
      "Trainable params: 34,561\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 16.9087 - val_loss: 13.9129\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.6752 - val_loss: 14.0780\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.5811 - val_loss: 14.3001\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.4816 - val_loss: 13.9322\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.4455 - val_loss: 14.4130\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.3630 - val_loss: 13.8706\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.3394 - val_loss: 14.0114\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.3104 - val_loss: 14.0448\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.2459 - val_loss: 14.4152\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.2271 - val_loss: 14.3059\n",
      "Epoch 11/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.1964 - val_loss: 14.7580\n",
      "4148/4148 [==============================] - 3s 616us/step\n",
      "RMSE on valid data: 3.724330067807499\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,817\n",
      "Trainable params: 34,561\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 17.0703 - val_loss: 13.9162\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.9095 - val_loss: 13.8308\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.8203 - val_loss: 13.7499\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7735 - val_loss: 13.7762\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.7406 - val_loss: 13.8588\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.6987 - val_loss: 13.6881\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.6880 - val_loss: 13.7229\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.6659 - val_loss: 13.6694\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.6352 - val_loss: 13.7066\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.6366 - val_loss: 13.6858\n",
      "Epoch 11/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.6137 - val_loss: 13.6889\n",
      "Epoch 12/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.6124 - val_loss: 13.6542\n",
      "Epoch 13/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 15.6310 - val_loss: 13.6689\n",
      "Epoch 14/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 15.5945 - val_loss: 13.6527\n",
      "Epoch 15/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 15.5864 - val_loss: 13.8626\n",
      "Epoch 16/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 15.5548 - val_loss: 13.6807\n",
      "Epoch 17/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 15.6081 - val_loss: 13.6587\n",
      "Epoch 18/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.5719 - val_loss: 13.7568\n",
      "Epoch 19/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 15.5618 - val_loss: 13.6662\n",
      "4148/4148 [==============================] - 3s 685us/step\n",
      "RMSE on valid data: 3.69495518140861\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,817\n",
      "Trainable params: 34,561\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 8s 2ms/step - loss: 17.5050 - val_loss: 14.3835\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3889 - val_loss: 14.3547\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3330 - val_loss: 14.3665\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3449 - val_loss: 14.3682\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3294 - val_loss: 14.3080\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3151 - val_loss: 14.3418\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3040 - val_loss: 14.3496\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.3018 - val_loss: 14.3407\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.2748 - val_loss: 14.3585\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 7s 2ms/step - loss: 16.2905 - val_loss: 14.3112\n",
      "4148/4148 [==============================] - 3s 612us/step\n",
      "RMSE on valid data: 3.782596647114941\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,633\n",
      "Trainable params: 69,121\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 10s 2ms/step - loss: 16.6255 - val_loss: 14.1010\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 9s 2ms/step - loss: 15.5608 - val_loss: 14.1431\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 9s 2ms/step - loss: 15.4307 - val_loss: 14.4654\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 9s 2ms/step - loss: 15.3459 - val_loss: 14.1625\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 9s 2ms/step - loss: 15.2804 - val_loss: 14.0872\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 9s 2ms/step - loss: 15.2149 - val_loss: 14.2810\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 9s 2ms/step - loss: 15.1551 - val_loss: 14.3623\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 9s 2ms/step - loss: 15.1186 - val_loss: 14.5749\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 9s 2ms/step - loss: 15.0835 - val_loss: 14.3699\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 9s 2ms/step - loss: 15.0304 - val_loss: 14.5101\n",
      "4148/4148 [==============================] - 3s 654us/step\n",
      "RMSE on valid data: 3.7532908438415253\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,633\n",
      "Trainable params: 69,121\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 13s 3ms/step - loss: 16.8283 - val_loss: 14.0089\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.8122 - val_loss: 13.9113\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.7273 - val_loss: 13.7396\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.6602 - val_loss: 13.6933\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.6171 - val_loss: 13.7026\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.5940 - val_loss: 13.7305\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.5794 - val_loss: 13.6920\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.5513 - val_loss: 13.6750\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.5251 - val_loss: 13.6295\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.5094 - val_loss: 13.7882\n",
      "Epoch 11/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.4850 - val_loss: 13.7121\n",
      "Epoch 12/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.4912 - val_loss: 13.6512\n",
      "Epoch 13/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.4707 - val_loss: 13.6073\n",
      "Epoch 14/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.4395 - val_loss: 13.6383\n",
      "Epoch 15/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.4463 - val_loss: 13.6458\n",
      "Epoch 16/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.4450 - val_loss: 13.6113\n",
      "Epoch 17/50\n",
      "3982/3982 [==============================] - 12s 3ms/step - loss: 15.4229 - val_loss: 13.6197\n",
      "Epoch 18/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 15.4249 - val_loss: 13.6164\n",
      "4148/4148 [==============================] - 3s 786us/step\n",
      "RMSE on valid data: 3.6888018385982098\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,633\n",
      "Trainable params: 69,121\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 12s 3ms/step - loss: 17.2713 - val_loss: 14.3891\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 16.3512 - val_loss: 14.4852\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 16.3341 - val_loss: 14.3433\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 16.3045 - val_loss: 14.3419\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 16.2794 - val_loss: 14.3103\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 16.2709 - val_loss: 14.5091\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 16.2571 - val_loss: 14.3510\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 16.2480 - val_loss: 14.4271\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 16.2532 - val_loss: 14.3171\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 11s 3ms/step - loss: 16.2533 - val_loss: 14.3332\n",
      "4148/4148 [==============================] - 3s 784us/step\n",
      "RMSE on valid data: 3.78289536741385\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,265\n",
      "Trainable params: 138,241\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 16.4066 - val_loss: 13.8245\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 15.5172 - val_loss: 13.9864\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 15.3591 - val_loss: 14.2060\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 15.2530 - val_loss: 14.0420\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 15.1715 - val_loss: 14.4730\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 15.0816 - val_loss: 14.2940\n",
      "4148/4148 [==============================] - 3s 710us/step\n",
      "RMSE on valid data: 3.718127990309272\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,265\n",
      "Trainable params: 138,241\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 16.6979 - val_loss: 14.0375\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 15.7730 - val_loss: 14.1803\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 15.7018 - val_loss: 13.8040\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.6086 - val_loss: 13.7924\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.5646 - val_loss: 13.7268\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.5335 - val_loss: 13.7396\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.4942 - val_loss: 13.6996\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.4689 - val_loss: 13.7382\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.4489 - val_loss: 13.6652\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.4298 - val_loss: 13.6119\n",
      "Epoch 11/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.4240 - val_loss: 13.6116\n",
      "Epoch 12/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.4018 - val_loss: 13.6521\n",
      "Epoch 13/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.3847 - val_loss: 13.5981\n",
      "Epoch 14/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.3650 - val_loss: 13.6622\n",
      "Epoch 15/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.3424 - val_loss: 13.6090\n",
      "Epoch 16/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.3568 - val_loss: 13.5841\n",
      "Epoch 17/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.3428 - val_loss: 13.5907\n",
      "Epoch 18/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.3183 - val_loss: 13.5853\n",
      "Epoch 19/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.3230 - val_loss: 13.6743\n",
      "Epoch 20/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.2966 - val_loss: 13.7554\n",
      "Epoch 21/50\n",
      "3982/3982 [==============================] - 14s 3ms/step - loss: 15.3053 - val_loss: 13.7277\n",
      "4148/4148 [==============================] - 3s 676us/step\n",
      "RMSE on valid data: 3.6856643021433855\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,265\n",
      "Trainable params: 138,241\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 17.1877 - val_loss: 14.5641\n",
      "Epoch 2/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 16.3602 - val_loss: 14.5743\n",
      "Epoch 3/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 16.2948 - val_loss: 14.6316\n",
      "Epoch 4/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 16.2853 - val_loss: 14.4006\n",
      "Epoch 5/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 16.2664 - val_loss: 14.3390\n",
      "Epoch 6/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 16.2539 - val_loss: 14.3929\n",
      "Epoch 7/50\n",
      "3982/3982 [==============================] - 14s 4ms/step - loss: 16.2349 - val_loss: 14.3207\n",
      "Epoch 8/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 16.2457 - val_loss: 14.4710\n",
      "Epoch 9/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 16.2182 - val_loss: 14.3364\n",
      "Epoch 10/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 16.2227 - val_loss: 14.3846\n",
      "Epoch 11/50\n",
      "3982/3982 [==============================] - 17s 4ms/step - loss: 16.2095 - val_loss: 14.3270\n",
      "Epoch 12/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 16.2208 - val_loss: 14.3024\n",
      "Epoch 13/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 16.2041 - val_loss: 14.2992\n",
      "Epoch 14/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 16.2136 - val_loss: 14.3102\n",
      "Epoch 15/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 16.2042 - val_loss: 14.4906\n",
      "Epoch 16/50\n",
      "3982/3982 [==============================] - 16s 4ms/step - loss: 16.2064 - val_loss: 14.3056\n",
      "Epoch 17/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 16.2055 - val_loss: 14.3377\n",
      "Epoch 18/50\n",
      "3982/3982 [==============================] - 15s 4ms/step - loss: 16.1856 - val_loss: 14.3096\n",
      "4148/4148 [==============================] - 3s 680us/step\n",
      "RMSE on valid data: 3.7814244643509007\n"
     ]
    }
   ],
   "source": [
    "mod1 = train_nn(neurons, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6488fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 hidden layers\n",
    "def nn_model2(n,a):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_dim = X_train.shape[1], activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    n = n/2\n",
    "    model.add(Dense(n,  activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation = 'linear'))\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbbfb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(neurons, activations):\n",
    "    es = EarlyStopping(monitor = 'val_loss', mode='min', patience = 5, restore_best_weights = True)\n",
    "    for n in neurons:\n",
    "        for a in activations:\n",
    "            nn_mod = nn_model2(n,a)\n",
    "            print(nn_mod.summary())\n",
    "            nn_mod.fit(X_train, y_train, batch_size = 150, epochs = 100, validation_data=(X_valid, y_valid), callbacks=[es])\n",
    "            pred = nn_mod.predict(X_valid)\n",
    "            print('RMSE on valid data:', sqrt(mse(y_valid, pred)))\n",
    "            keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78d69326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 19.6660 - val_loss: 13.8311\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.7169 - val_loss: 13.7492\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.5402 - val_loss: 13.7429\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.4036 - val_loss: 13.6369\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.3294 - val_loss: 13.6393\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.2638 - val_loss: 13.6108\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.2118 - val_loss: 13.6138\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.1542 - val_loss: 13.5923\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.1300 - val_loss: 13.6137\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.0765 - val_loss: 13.5872\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.0209 - val_loss: 13.5375\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.0245 - val_loss: 13.5389\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.9724 - val_loss: 13.5383\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.9770 - val_loss: 13.6287\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.9536 - val_loss: 13.6754\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.9334 - val_loss: 13.6098\n",
      "4148/4148 [==============================] - 2s 534us/step\n",
      "RMSE on valid data: 3.679332051644664\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 19.4452 - val_loss: 13.8880\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.6433 - val_loss: 13.8278\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.4703 - val_loss: 13.7620\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.3790 - val_loss: 13.7468\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.2866 - val_loss: 13.7322\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.2477 - val_loss: 13.7108\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.1985 - val_loss: 13.7251\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.1792 - val_loss: 13.6752\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.1651 - val_loss: 13.7298\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.1231 - val_loss: 13.6564\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.1247 - val_loss: 13.6538\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.0701 - val_loss: 13.6358\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.0736 - val_loss: 13.6802\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.0453 - val_loss: 13.7050\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.0575 - val_loss: 13.6253\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.9948 - val_loss: 13.6320\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.9715 - val_loss: 13.6520\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 15.9981 - val_loss: 13.6265\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.0143 - val_loss: 13.6288\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.0228 - val_loss: 13.6704\n",
      "4148/4148 [==============================] - 2s 542us/step\n",
      "RMSE on valid data: 3.691254176168776\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,185\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 19.7993 - val_loss: 14.3301\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 17.0775 - val_loss: 14.3193\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.8916 - val_loss: 14.3226\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.8516 - val_loss: 14.3180\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.8184 - val_loss: 14.2961\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.7986 - val_loss: 14.3001\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.7311 - val_loss: 14.2912\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.7197 - val_loss: 14.3111\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.7139 - val_loss: 14.2909\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.7087 - val_loss: 14.3046\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.6799 - val_loss: 14.2917\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.6603 - val_loss: 14.2990\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.6709 - val_loss: 14.2982\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 4s 2ms/step - loss: 16.6405 - val_loss: 14.3159\n",
      "4148/4148 [==============================] - 2s 522us/step\n",
      "RMSE on valid data: 3.7803280486575863\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,585\n",
      "Trainable params: 19,393\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 7s 2ms/step - loss: 18.7480 - val_loss: 13.7722\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.3128 - val_loss: 13.6603\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1328 - val_loss: 13.7276\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.0437 - val_loss: 13.7736\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.9602 - val_loss: 13.8198\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8968 - val_loss: 13.7600\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8553 - val_loss: 13.8801\n",
      "4148/4148 [==============================] - 2s 525us/step\n",
      "RMSE on valid data: 3.6959830229790507\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,585\n",
      "Trainable params: 19,393\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 7s 2ms/step - loss: 18.5843 - val_loss: 13.8411\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.2590 - val_loss: 13.7751\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1115 - val_loss: 13.7419\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.0265 - val_loss: 13.7492\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.9430 - val_loss: 13.6584\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8935 - val_loss: 13.7052\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8746 - val_loss: 13.6393\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8665 - val_loss: 13.6177\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8004 - val_loss: 13.6423\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8009 - val_loss: 13.6254\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7881 - val_loss: 13.5929\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7720 - val_loss: 13.5845\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7553 - val_loss: 13.6039\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7496 - val_loss: 13.6030\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.7183 - val_loss: 13.5616\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7055 - val_loss: 13.5754\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.6850 - val_loss: 13.5680\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.6876 - val_loss: 13.6088\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.6610 - val_loss: 13.5487\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.6960 - val_loss: 13.5580\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.6777 - val_loss: 13.5683\n",
      "Epoch 22/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.6522 - val_loss: 13.5756\n",
      "Epoch 23/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.6252 - val_loss: 13.5618\n",
      "Epoch 24/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.6527 - val_loss: 13.5704\n",
      "4148/4148 [==============================] - 3s 598us/step\n",
      "RMSE on valid data: 3.680856129720574\n",
      "Model: \"sequential\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,585\n",
      "Trainable params: 19,393\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 7s 2ms/step - loss: 18.9408 - val_loss: 14.3057\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6881 - val_loss: 14.2869\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6585 - val_loss: 14.3064\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5744 - val_loss: 14.3008\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5528 - val_loss: 14.2967\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5675 - val_loss: 14.3312\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5529 - val_loss: 14.2862\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5415 - val_loss: 14.3023\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5110 - val_loss: 14.2864\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5042 - val_loss: 14.2839\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4702 - val_loss: 14.3125\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4557 - val_loss: 14.2972\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4620 - val_loss: 14.2827\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4664 - val_loss: 14.2869\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4615 - val_loss: 14.2914\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4602 - val_loss: 14.2815\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4391 - val_loss: 14.2906\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4522 - val_loss: 14.2880\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4383 - val_loss: 14.2886\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4167 - val_loss: 14.2882\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4236 - val_loss: 14.3389\n",
      "4148/4148 [==============================] - 2s 522us/step\n",
      "RMSE on valid data: 3.779081952405726\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,265\n",
      "Trainable params: 42,881\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 17.9360 - val_loss: 13.7810\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.9467 - val_loss: 13.7606\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.7881 - val_loss: 13.7980\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.6604 - val_loss: 14.0599\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.5920 - val_loss: 14.2343\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.4934 - val_loss: 14.1785\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.4100 - val_loss: 14.5317\n",
      "4148/4148 [==============================] - 3s 669us/step\n",
      "RMSE on valid data: 3.709528381902006\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,265\n",
      "Trainable params: 42,881\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 17.9227 - val_loss: 13.7822\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.9904 - val_loss: 13.7530\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.8796 - val_loss: 13.6772\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.7545 - val_loss: 13.6922\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.7105 - val_loss: 13.6753\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.6636 - val_loss: 13.6146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.6240 - val_loss: 13.6152\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.6098 - val_loss: 13.6427\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.5744 - val_loss: 13.5977\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.5746 - val_loss: 13.5818\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.5270 - val_loss: 13.5910\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.5111 - val_loss: 13.5455\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.4855 - val_loss: 13.5893\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.4906 - val_loss: 13.5224\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.4637 - val_loss: 13.6190\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.4478 - val_loss: 13.5357\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.4355 - val_loss: 13.6288\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.4412 - val_loss: 13.5149\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.4306 - val_loss: 13.4874\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.3751 - val_loss: 13.5223\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.4097 - val_loss: 13.5025\n",
      "Epoch 22/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.3997 - val_loss: 13.5129\n",
      "Epoch 23/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.3983 - val_loss: 13.5691\n",
      "Epoch 24/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.3818 - val_loss: 13.4932\n",
      "4148/4148 [==============================] - 3s 765us/step\n",
      "RMSE on valid data: 3.672521119804115\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,265\n",
      "Trainable params: 42,881\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 18.3759 - val_loss: 14.3632\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.5476 - val_loss: 14.3016\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.4523 - val_loss: 14.3297\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.4381 - val_loss: 14.3155\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.3881 - val_loss: 14.4698\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.3968 - val_loss: 14.3373\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.3737 - val_loss: 14.3023\n",
      "4148/4148 [==============================] - 3s 753us/step\n",
      "RMSE on valid data: 3.7817501337162596\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,913\n",
      "Trainable params: 102,145\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 14s 5ms/step - loss: 17.4830 - val_loss: 13.7928\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 15.7471 - val_loss: 13.6928\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 15.5513 - val_loss: 13.8978\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 15.4431 - val_loss: 13.8093\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 15.3394 - val_loss: 14.4484\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 15.2570 - val_loss: 14.4581\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 15.1954 - val_loss: 15.0448\n",
      "4148/4148 [==============================] - 4s 968us/step\n",
      "RMSE on valid data: 3.700384139573076\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,913\n",
      "Trainable params: 102,145\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 13s 5ms/step - loss: 17.5174 - val_loss: 13.7566\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.8416 - val_loss: 13.9832\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.7082 - val_loss: 13.9268\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.6241 - val_loss: 13.6933\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.5434 - val_loss: 13.6766\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.5009 - val_loss: 13.7575\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4809 - val_loss: 13.5675\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4368 - val_loss: 13.5608\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4048 - val_loss: 13.5522\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.3761 - val_loss: 13.5537\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.3622 - val_loss: 13.5283\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.3435 - val_loss: 13.5533\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.3151 - val_loss: 13.5578\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2881 - val_loss: 13.5883\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2890 - val_loss: 13.5633\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.2686 - val_loss: 13.4819\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.2633 - val_loss: 13.4947\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.2502 - val_loss: 13.6523\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.2395 - val_loss: 13.5299\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2292 - val_loss: 13.5019\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.2327 - val_loss: 13.5177\n",
      "4148/4148 [==============================] - 4s 848us/step\n",
      "RMSE on valid data: 3.6717770140036263\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,913\n",
      "Trainable params: 102,145\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 12s 4ms/step - loss: 17.9492 - val_loss: 14.3767\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.4095 - val_loss: 14.3269\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.3294 - val_loss: 14.3631\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2916 - val_loss: 14.3458\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2903 - val_loss: 14.3058\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2886 - val_loss: 14.3001\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2757 - val_loss: 14.2925\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2568 - val_loss: 14.3106\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 16.2495 - val_loss: 14.3338\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 16.2330 - val_loss: 14.3069\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2385 - val_loss: 14.2888\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2263 - val_loss: 14.3189\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2201 - val_loss: 14.3958\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2018 - val_loss: 14.3582\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2065 - val_loss: 14.2924\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1905 - val_loss: 14.3329\n",
      "4148/4148 [==============================] - 3s 813us/step\n",
      "RMSE on valid data: 3.7800584362591576\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,361\n",
      "Trainable params: 269,825\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 19s 7ms/step - loss: 17.1836 - val_loss: 13.7937\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 15.6557 - val_loss: 13.7598\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 15.4696 - val_loss: 13.6667\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 15.3155 - val_loss: 13.7973\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 15.1846 - val_loss: 14.0177\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 15.0719 - val_loss: 15.3449\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 14.9580 - val_loss: 17.1069\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 14.8350 - val_loss: 15.9825\n",
      "4148/4148 [==============================] - 5s 1ms/step\n",
      "RMSE on valid data: 3.6968474086251137\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,361\n",
      "Trainable params: 269,825\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 17.1938 - val_loss: 13.7812\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.7648 - val_loss: 13.8036\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.6322 - val_loss: 13.6345\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.5364 - val_loss: 13.6562\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.4784 - val_loss: 13.6087\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.4252 - val_loss: 13.5606\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.3889 - val_loss: 13.7265\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.3250 - val_loss: 13.5936\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.3189 - val_loss: 13.6593\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.2897 - val_loss: 13.5347\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.2419 - val_loss: 13.6116\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.2126 - val_loss: 13.5038\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.2070 - val_loss: 13.5607\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.2077 - val_loss: 13.5621\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 39s 15ms/step - loss: 15.1645 - val_loss: 13.5115\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.1532 - val_loss: 13.4996\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.1199 - val_loss: 13.4523\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.1160 - val_loss: 13.4558\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.0815 - val_loss: 13.4908\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.0985 - val_loss: 13.4581\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.0477 - val_loss: 13.5128\n",
      "Epoch 22/100\n",
      "2655/2655 [==============================] - 38s 14ms/step - loss: 15.0475 - val_loss: 13.4571\n",
      "4148/4148 [==============================] - 10s 2ms/step\n",
      "RMSE on valid data: 3.6677330564984953\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,361\n",
      "Trainable params: 269,825\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 37s 14ms/step - loss: 17.6613 - val_loss: 14.3575\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 36s 13ms/step - loss: 16.3727 - val_loss: 14.5715\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 36s 13ms/step - loss: 16.2647 - val_loss: 14.3662\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 36s 14ms/step - loss: 16.2630 - val_loss: 14.3191\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 36s 14ms/step - loss: 16.2363 - val_loss: 14.4963\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 36s 14ms/step - loss: 16.2004 - val_loss: 14.4671\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 36s 13ms/step - loss: 16.2183 - val_loss: 14.3924\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 36s 14ms/step - loss: 16.1912 - val_loss: 14.3031\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 36s 14ms/step - loss: 16.1712 - val_loss: 14.3127\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 36s 13ms/step - loss: 16.1768 - val_loss: 14.3169\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 36s 13ms/step - loss: 16.1600 - val_loss: 14.3755\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 36s 13ms/step - loss: 16.1720 - val_loss: 14.3080\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 36s 13ms/step - loss: 16.1529 - val_loss: 14.3350\n",
      "4148/4148 [==============================] - 9s 2ms/step\n",
      "RMSE on valid data: 3.7819423541020374\n"
     ]
    }
   ],
   "source": [
    "mod2 = train_nn(neurons, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22681808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 hidden layers\n",
    "\n",
    "def nn_model3(n,a):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_dim = X_train.shape[1], activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    n = n/2\n",
    "    model.add(Dense(n,  activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    n = n/4\n",
    "    model.add(Dense(n,  activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=1, activation = 'linear'))\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99fe2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(neurons,activations):\n",
    "    es = EarlyStopping(monitor = 'val_loss', mode='min', patience = 5, restore_best_weights = True)\n",
    "    for n in neurons:\n",
    "        for a in activations:\n",
    "            nn_mod = nn_model3(n,a)\n",
    "            print(nn_mod.summary())\n",
    "            nn_mod.fit(X_train, y_train, batch_size = 150, epochs = 100, validation_data=(X_valid, y_valid), callbacks=[es])\n",
    "            pred = nn_mod.predict(X_valid)\n",
    "            print('RMSE on valid data:', sqrt(mse(y_valid, pred)))\n",
    "            keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "835cc53b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,353\n",
      "Trainable params: 9,249\n",
      "Non-trainable params: 104\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 7s 2ms/step - loss: 21.1011 - val_loss: 13.8809\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.3488 - val_loss: 13.7909\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.2070 - val_loss: 13.6861\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1086 - val_loss: 13.6800\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.0189 - val_loss: 13.6556\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 15.9841 - val_loss: 13.6952\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 15.9288 - val_loss: 13.6614\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 15.8789 - val_loss: 13.7660\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 15.8434 - val_loss: 13.7512\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8005 - val_loss: 14.3012\n",
      "4148/4148 [==============================] - 2s 573us/step\n",
      "RMSE on valid data: 3.6953491657642203\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,353\n",
      "Trainable params: 9,249\n",
      "Non-trainable params: 104\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 7s 2ms/step - loss: 20.7686 - val_loss: 13.8688\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1366 - val_loss: 13.7712\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.0081 - val_loss: 13.7545\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.9363 - val_loss: 13.7079\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8924 - val_loss: 13.7449\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8302 - val_loss: 13.6936\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8159 - val_loss: 13.6964\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.8055 - val_loss: 13.6894\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7647 - val_loss: 13.6814\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7562 - val_loss: 13.6948\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7582 - val_loss: 13.6513\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7432 - val_loss: 13.6816\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7423 - val_loss: 13.6536\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7083 - val_loss: 13.6981\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7133 - val_loss: 13.6890\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 15.7079 - val_loss: 13.6601\n",
      "4148/4148 [==============================] - 2s 579us/step\n",
      "RMSE on valid data: 3.6947660799085944\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 9,353\n",
      "Trainable params: 9,249\n",
      "Non-trainable params: 104\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 7s 2ms/step - loss: 20.8188 - val_loss: 14.3242\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6490 - val_loss: 14.2941\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.6017 - val_loss: 14.2938\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5597 - val_loss: 14.3365\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 5s 2ms/step - loss: 16.5602 - val_loss: 14.3533\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5383 - val_loss: 14.3081\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5274 - val_loss: 14.3085\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5116 - val_loss: 14.3089\n",
      "4148/4148 [==============================] - 2s 565us/step\n",
      "RMSE on valid data: 3.7807101826117653\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,857\n",
      "Trainable params: 19,649\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 19.6979 - val_loss: 13.7554\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.9884 - val_loss: 13.7194\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.8596 - val_loss: 13.6102\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.7533 - val_loss: 13.6581\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.6696 - val_loss: 13.6725\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.6394 - val_loss: 13.6600\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.5961 - val_loss: 13.6126\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 15.5312 - val_loss: 13.6452\n",
      "4148/4148 [==============================] - 2s 572us/step\n",
      "RMSE on valid data: 3.6892046736514112\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,857\n",
      "Trainable params: 19,649\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 19.5251 - val_loss: 13.8454\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.8723 - val_loss: 13.7656\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.7541 - val_loss: 13.7281\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.6697 - val_loss: 13.6590\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.6272 - val_loss: 13.6308\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.5901 - val_loss: 13.7288\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.5910 - val_loss: 13.6609\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.5644 - val_loss: 13.6356\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.5259 - val_loss: 13.7255\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 15.5113 - val_loss: 13.6890\n",
      "4148/4148 [==============================] - 2s 569us/step\n",
      "RMSE on valid data: 3.691988854482624\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,857\n",
      "Trainable params: 19,649\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 19.5791 - val_loss: 14.2989\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.4257 - val_loss: 14.3234\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.4098 - val_loss: 14.3104\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.3527 - val_loss: 14.3014\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.3407 - val_loss: 14.2945\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.3176 - val_loss: 14.3395\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.2985 - val_loss: 14.3053\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.2933 - val_loss: 14.2914\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.2610 - val_loss: 14.3385\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.2631 - val_loss: 14.2901\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.2668 - val_loss: 14.3783\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.2299 - val_loss: 14.2980\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.2496 - val_loss: 14.3210\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.2289 - val_loss: 14.3316\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 7s 3ms/step - loss: 16.2274 - val_loss: 14.3719\n",
      "4148/4148 [==============================] - 2s 561us/step\n",
      "RMSE on valid data: 3.7802260127873\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,321\n",
      "Trainable params: 43,905\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 18.2047 - val_loss: 13.8464\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.7384 - val_loss: 13.9254\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.5855 - val_loss: 13.7781\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.4889 - val_loss: 13.8095\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.3943 - val_loss: 13.6993\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.3460 - val_loss: 13.8778\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2894 - val_loss: 13.9346\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2423 - val_loss: 14.3261\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.1857 - val_loss: 13.6402\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.1379 - val_loss: 14.0244\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 9s 4ms/step - loss: 15.0299 - val_loss: 14.4241\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.0024 - val_loss: 13.9236\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 9s 4ms/step - loss: 14.9910 - val_loss: 14.9009\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 9s 4ms/step - loss: 14.8941 - val_loss: 13.8238\n",
      "4148/4148 [==============================] - 4s 1ms/step\n",
      "RMSE on valid data: 3.6932599841545732\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,321\n",
      "Trainable params: 43,905\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 18.3565 - val_loss: 13.7413\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.6990 - val_loss: 13.7285\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.5651 - val_loss: 13.6259\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.4852 - val_loss: 13.5764\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.4442 - val_loss: 13.6047\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.4096 - val_loss: 13.6029\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.3822 - val_loss: 13.5317\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.3546 - val_loss: 13.5272\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.3422 - val_loss: 13.5001\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.3130 - val_loss: 13.5139\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2964 - val_loss: 13.4928\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2840 - val_loss: 13.4980\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2732 - val_loss: 13.4977\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2515 - val_loss: 13.4929\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2426 - val_loss: 13.5003\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2193 - val_loss: 13.4699\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2143 - val_loss: 13.5577\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.2009 - val_loss: 13.4911\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.1863 - val_loss: 13.4498\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.1788 - val_loss: 13.5046\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.1809 - val_loss: 13.5147\n",
      "Epoch 22/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.1839 - val_loss: 13.4583\n",
      "Epoch 23/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.1683 - val_loss: 13.4660\n",
      "Epoch 24/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 15.1385 - val_loss: 13.4596\n",
      "4148/4148 [==============================] - 4s 948us/step\n",
      "RMSE on valid data: 3.6673968917859128\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,321\n",
      "Trainable params: 43,905\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 18.8852 - val_loss: 14.3844\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.3337 - val_loss: 14.4010\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2656 - val_loss: 14.3181\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.2343 - val_loss: 14.3319\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1947 - val_loss: 14.3150\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1719 - val_loss: 14.3053\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1802 - val_loss: 14.3563\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1597 - val_loss: 14.3270\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1457 - val_loss: 14.2927\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1324 - val_loss: 14.2849\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1380 - val_loss: 14.2840\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1183 - val_loss: 14.3699\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1183 - val_loss: 14.2962\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1121 - val_loss: 14.2867\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1174 - val_loss: 14.3027\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 10s 4ms/step - loss: 16.1226 - val_loss: 14.2915\n",
      "4148/4148 [==============================] - 4s 941us/step\n",
      "RMSE on valid data: 3.77942311177357\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,073\n",
      "Trainable params: 106,241\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 19s 7ms/step - loss: 17.6232 - val_loss: 13.7331\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 18s 7ms/step - loss: 15.5523 - val_loss: 13.6615\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 18s 7ms/step - loss: 15.4078 - val_loss: 13.7202\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 18s 7ms/step - loss: 15.2861 - val_loss: 14.0960\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 18s 7ms/step - loss: 15.1937 - val_loss: 13.6922\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 18s 7ms/step - loss: 15.0749 - val_loss: 14.1229\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 18s 7ms/step - loss: 14.9954 - val_loss: 14.1796\n",
      "4148/4148 [==============================] - 5s 1ms/step\n",
      "RMSE on valid data: 3.6961406104765997\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,073\n",
      "Trainable params: 106,241\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 21s 7ms/step - loss: 17.5129 - val_loss: 13.7687\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.6099 - val_loss: 13.6960\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.4893 - val_loss: 13.6139\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.3988 - val_loss: 13.6238\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 15.3481 - val_loss: 13.6230\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.3007 - val_loss: 13.5553\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 15.2652 - val_loss: 13.5607\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.2211 - val_loss: 13.5332\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.2177 - val_loss: 13.5106\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.1907 - val_loss: 13.4845\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.1582 - val_loss: 13.4776\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 18s 7ms/step - loss: 15.1516 - val_loss: 13.4940\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.1268 - val_loss: 13.4594\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.1079 - val_loss: 13.5278\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.0783 - val_loss: 13.4310\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.0621 - val_loss: 13.4354\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.0643 - val_loss: 13.4843\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.0474 - val_loss: 13.4489\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 15.0357 - val_loss: 13.4352\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 17s 7ms/step - loss: 14.9938 - val_loss: 13.4923\n",
      "4148/4148 [==============================] - 5s 1ms/step\n",
      "RMSE on valid data: 3.6648285639214566\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,073\n",
      "Trainable params: 106,241\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 18s 7ms/step - loss: 18.1358 - val_loss: 14.3857\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.2593 - val_loss: 14.3235\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.1988 - val_loss: 14.3039\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.1436 - val_loss: 14.3031\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.1090 - val_loss: 14.3105\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.0946 - val_loss: 14.3057\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.0821 - val_loss: 14.3220\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.0765 - val_loss: 14.2850\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.0615 - val_loss: 14.4419\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.0857 - val_loss: 14.3233\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.0744 - val_loss: 14.2948\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.0611 - val_loss: 14.2860\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 17s 6ms/step - loss: 16.0656 - val_loss: 14.2960\n",
      "4148/4148 [==============================] - 5s 1ms/step\n",
      "RMSE on valid data: 3.779551618145495\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,873\n",
      "Trainable params: 286,209\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 33s 12ms/step - loss: 17.1641 - val_loss: 14.3165\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 33s 12ms/step - loss: 15.5022 - val_loss: 13.7470\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 15.3224 - val_loss: 13.8455\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 15.1885 - val_loss: 13.7324\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 15.0656 - val_loss: 14.0027\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 14.9461 - val_loss: 13.9276\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 14.8474 - val_loss: 13.7732\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 14.7190 - val_loss: 14.1977\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 14.6010 - val_loss: 14.5543\n",
      "4148/4148 [==============================] - 8s 2ms/step\n",
      "RMSE on valid data: 3.7057204970320288\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,873\n",
      "Trainable params: 286,209\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 31s 11ms/step - loss: 17.1012 - val_loss: 13.8498\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.5577 - val_loss: 13.7458\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.4380 - val_loss: 13.7166\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.3621 - val_loss: 13.5763\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.3108 - val_loss: 13.5332\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.2560 - val_loss: 13.5698\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.2319 - val_loss: 13.5081\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.1883 - val_loss: 13.4942\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.1380 - val_loss: 13.5359\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.1325 - val_loss: 13.4833\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.1051 - val_loss: 13.5176\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.0647 - val_loss: 13.5500\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.0420 - val_loss: 13.4720\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 15.0202 - val_loss: 13.4564\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.9790 - val_loss: 13.4440\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.9703 - val_loss: 13.5365\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.9447 - val_loss: 13.5609\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.9157 - val_loss: 13.4634\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.9083 - val_loss: 13.5253\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.8808 - val_loss: 13.4428\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.8601 - val_loss: 13.4179\n",
      "Epoch 22/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.8188 - val_loss: 13.5411\n",
      "Epoch 23/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.8113 - val_loss: 13.4829\n",
      "Epoch 24/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.7838 - val_loss: 13.4535\n",
      "Epoch 25/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.7697 - val_loss: 13.4344\n",
      "Epoch 26/100\n",
      "2655/2655 [==============================] - 30s 11ms/step - loss: 14.7640 - val_loss: 13.5880\n",
      "4148/4148 [==============================] - 8s 2ms/step\n",
      "RMSE on valid data: 3.6630492659921883\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 286,209\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 17.6144 - val_loss: 14.4919\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.2064 - val_loss: 14.3952\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.1546 - val_loss: 14.3703\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.1246 - val_loss: 14.3062\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.1047 - val_loss: 14.3340\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0957 - val_loss: 14.3199\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0850 - val_loss: 14.3099\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0721 - val_loss: 14.3051\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0511 - val_loss: 14.3634\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0539 - val_loss: 14.3074\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0401 - val_loss: 14.4372\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0442 - val_loss: 14.2997\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0389 - val_loss: 14.2906\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0279 - val_loss: 14.2876\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0336 - val_loss: 14.2932\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0317 - val_loss: 14.2956\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0360 - val_loss: 14.3104\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0148 - val_loss: 14.3715\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 31s 12ms/step - loss: 16.0290 - val_loss: 14.2879\n",
      "4148/4148 [==============================] - 8s 2ms/step\n",
      "RMSE on valid data: 3.7798971920654196\n"
     ]
    }
   ],
   "source": [
    "mod3 = train_nn(neurons, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97f7c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 hidden layers\n",
    "\n",
    "def nn_model4(n,a):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_dim = X_train.shape[1], activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    n = n/2\n",
    "    model.add(Dense(n,  activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    n = n/4\n",
    "    model.add(Dense(n,  activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    n = n/2\n",
    "    model.add(Dense(n,  activation = a))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=1, activation = 'linear'))\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59b8f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(neurons,activations):\n",
    "    es = EarlyStopping(monitor = 'val_loss', mode='min', patience = 5, restore_best_weights = True)\n",
    "    for n in neurons:\n",
    "        for a in activations:\n",
    "            nn_mod = nn_model4(n,a)\n",
    "            print(nn_mod.summary())\n",
    "            nn_mod.fit(X_train, y_train, batch_size = 150, epochs = 100, validation_data=(X_valid, y_valid), callbacks=[es])\n",
    "            pred = nn_mod.predict(X_valid)\n",
    "            print('RMSE on valid data:', sqrt(mse(y_valid, pred)))\n",
    "            keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "198495e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2)                8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,369\n",
      "Trainable params: 9,261\n",
      "Non-trainable params: 108\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 8s 2ms/step - loss: 22.9211 - val_loss: 14.1887\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 17.1959 - val_loss: 14.1107\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.8239 - val_loss: 14.1010\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6347 - val_loss: 13.9441\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5010 - val_loss: 13.7964\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.4613 - val_loss: 13.7639\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.3402 - val_loss: 13.8417\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.3236 - val_loss: 13.8088\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.2885 - val_loss: 13.9195\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.2726 - val_loss: 13.7186\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.2780 - val_loss: 13.8225\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.2445 - val_loss: 13.7014\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.2245 - val_loss: 13.7068\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.2226 - val_loss: 13.6757\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.2081 - val_loss: 13.7081\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1854 - val_loss: 13.6354\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1443 - val_loss: 13.6638\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1690 - val_loss: 13.7375\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1552 - val_loss: 13.6244\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1584 - val_loss: 13.8410\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1430 - val_loss: 13.6112\n",
      "Epoch 22/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.0946 - val_loss: 13.6503\n",
      "Epoch 23/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1276 - val_loss: 13.6698\n",
      "Epoch 24/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.0805 - val_loss: 13.7494\n",
      "Epoch 25/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.1357 - val_loss: 13.6732\n",
      "Epoch 26/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.0808 - val_loss: 13.6161\n",
      "4148/4148 [==============================] - 3s 590us/step\n",
      "RMSE on valid data: 3.6893326028189017\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2)                8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,369\n",
      "Trainable params: 9,261\n",
      "Non-trainable params: 108\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 7s 2ms/step - loss: 22.1804 - val_loss: 13.9911\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.9029 - val_loss: 13.9206\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.8039 - val_loss: 13.8982\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.7556 - val_loss: 13.9102\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.7405 - val_loss: 13.9131\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.7558 - val_loss: 13.8309\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.7300 - val_loss: 13.8080\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6814 - val_loss: 13.8300\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6777 - val_loss: 13.8376\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6391 - val_loss: 13.8331\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6519 - val_loss: 13.9059\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6471 - val_loss: 13.7764\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6067 - val_loss: 13.8243\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6292 - val_loss: 13.7834\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6263 - val_loss: 13.7783\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.6213 - val_loss: 13.8301\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 16.5946 - val_loss: 13.7898\n",
      "4148/4148 [==============================] - 3s 585us/step\n",
      "RMSE on valid data: 3.711662487025361\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                8544      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2)                8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,369\n",
      "Trainable params: 9,261\n",
      "Non-trainable params: 108\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 7s 2ms/step - loss: 23.8010 - val_loss: 14.3479\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 17.4652 - val_loss: 14.3767\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 17.4338 - val_loss: 14.3702\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 17.4548 - val_loss: 14.3668\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 17.4570 - val_loss: 14.3729\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 6s 2ms/step - loss: 17.3969 - val_loss: 14.3882\n",
      "4148/4148 [==============================] - 3s 591us/step\n",
      "RMSE on valid data: 3.7878648965424584\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,905\n",
      "Trainable params: 19,689\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 10s 3ms/step - loss: 21.6138 - val_loss: 13.9118\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.5580 - val_loss: 13.7684\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.3546 - val_loss: 13.7165\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.2462 - val_loss: 13.6446\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.1272 - val_loss: 13.6733\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.0703 - val_loss: 13.7490\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.0008 - val_loss: 13.7184\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 15.9455 - val_loss: 13.7816\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 15.9222 - val_loss: 13.7335\n",
      "4148/4148 [==============================] - 3s 686us/step\n",
      "RMSE on valid data: 3.6938639340847055\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,905\n",
      "Trainable params: 19,689\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 10s 3ms/step - loss: 20.6721 - val_loss: 13.8548\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.3933 - val_loss: 13.7842\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.3029 - val_loss: 13.7282\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.1779 - val_loss: 13.7345\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.1321 - val_loss: 13.7072\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.0651 - val_loss: 13.6798\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 16.0246 - val_loss: 13.7127\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 15.9711 - val_loss: 13.7248\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 15.9396 - val_loss: 13.8932\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 15.8914 - val_loss: 13.8867\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 9s 3ms/step - loss: 15.8779 - val_loss: 13.8540\n",
      "4148/4148 [==============================] - 3s 605us/step\n",
      "RMSE on valid data: 3.6986165054311435\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                17088     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,905\n",
      "Trainable params: 19,689\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 10s 3ms/step - loss: 21.0240 - val_loss: 14.3512\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.9792 - val_loss: 14.3052\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.9156 - val_loss: 14.3366\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.8881 - val_loss: 14.3030\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.8706 - val_loss: 14.3335\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.8855 - val_loss: 14.4256\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.8621 - val_loss: 14.3531\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.8369 - val_loss: 14.3419\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 8s 3ms/step - loss: 16.8757 - val_loss: 14.3231\n",
      "4148/4148 [==============================] - 3s 582us/step\n",
      "RMSE on valid data: 3.7819279729212427\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 44,481\n",
      "Trainable params: 44,049\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 12s 4ms/step - loss: 19.7455 - val_loss: 13.7729\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 16.1022 - val_loss: 13.8173\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.9397 - val_loss: 13.8238\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.8168 - val_loss: 13.8380\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.7303 - val_loss: 13.9483\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 12s 4ms/step - loss: 15.6622 - val_loss: 14.0638\n",
      "4148/4148 [==============================] - 4s 974us/step\n",
      "RMSE on valid data: 3.711190095659767\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,481\n",
      "Trainable params: 44,049\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 13s 4ms/step - loss: 19.5674 - val_loss: 13.8633\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 16.1077 - val_loss: 13.8888\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.9233 - val_loss: 14.0535\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.7703 - val_loss: 13.6660\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.7113 - val_loss: 13.6651\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.6620 - val_loss: 13.6434\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.6053 - val_loss: 13.6586\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.5769 - val_loss: 13.6926\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.5338 - val_loss: 13.6186\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.5101 - val_loss: 13.6383\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4845 - val_loss: 13.5796\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4652 - val_loss: 13.6065\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4650 - val_loss: 13.6169\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4413 - val_loss: 13.5940\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4253 - val_loss: 13.5625\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4210 - val_loss: 13.5219\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.4253 - val_loss: 13.5794\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.3730 - val_loss: 13.6840\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.3635 - val_loss: 13.5280\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.3642 - val_loss: 13.5588\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 11s 4ms/step - loss: 15.3696 - val_loss: 13.6069\n",
      "4148/4148 [==============================] - 5s 1ms/step\n",
      "RMSE on valid data: 3.677213971654352\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,481\n",
      "Trainable params: 44,049\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 14s 5ms/step - loss: 19.4283 - val_loss: 14.3289\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 16.6353 - val_loss: 14.3248\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 16.5911 - val_loss: 14.2941\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 13s 5ms/step - loss: 16.5808 - val_loss: 14.2913\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2655/2655 [==============================] - 13s 5ms/step - loss: 16.5943 - val_loss: 14.2944\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 13s 5ms/step - loss: 16.5742 - val_loss: 14.2807\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 13s 5ms/step - loss: 16.5772 - val_loss: 14.3244\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 16.5748 - val_loss: 14.3128\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 12s 5ms/step - loss: 16.5564 - val_loss: 14.3217\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 13s 5ms/step - loss: 16.5524 - val_loss: 14.3142\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 13s 5ms/step - loss: 16.5664 - val_loss: 14.2966\n",
      "4148/4148 [==============================] - 4s 1ms/step\n",
      "RMSE on valid data: 3.7789865099186435\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,649\n",
      "Trainable params: 106,785\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 24s 9ms/step - loss: 18.4113 - val_loss: 13.8948\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 22s 8ms/step - loss: 15.8255 - val_loss: 13.7185\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.6363 - val_loss: 14.0802\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 23s 8ms/step - loss: 15.4945 - val_loss: 14.0465\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 23s 8ms/step - loss: 15.4168 - val_loss: 14.4809\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 23s 8ms/step - loss: 15.3095 - val_loss: 14.7102\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.2237 - val_loss: 16.7103\n",
      "4148/4148 [==============================] - 6s 2ms/step\n",
      "RMSE on valid data: 3.703847793136909\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,649\n",
      "Trainable params: 106,785\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 24s 9ms/step - loss: 18.2595 - val_loss: 13.8631\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.7864 - val_loss: 13.7496\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.6187 - val_loss: 13.6391\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.5463 - val_loss: 13.6332\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.4820 - val_loss: 13.5851\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.4525 - val_loss: 13.6057\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.4086 - val_loss: 13.5429\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.3629 - val_loss: 13.5646\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.3561 - val_loss: 13.6195\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.3227 - val_loss: 13.5142\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.2995 - val_loss: 13.5210\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.2903 - val_loss: 13.4792\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.2349 - val_loss: 13.5590\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.2429 - val_loss: 13.6158\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.2235 - val_loss: 13.5524\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.2221 - val_loss: 13.5071\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 15.1790 - val_loss: 13.4913\n",
      "4148/4148 [==============================] - 6s 2ms/step\n",
      "RMSE on valid data: 3.6713992203122694\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,649\n",
      "Trainable params: 106,785\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 25s 9ms/step - loss: 19.0114 - val_loss: 14.3774\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.4603 - val_loss: 14.3527\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.4024 - val_loss: 14.3009\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.3629 - val_loss: 14.3064\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.3111 - val_loss: 14.2984\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2907 - val_loss: 14.2947\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2522 - val_loss: 14.3616\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2562 - val_loss: 14.3006\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2285 - val_loss: 14.3457\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2320 - val_loss: 14.2846\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2374 - val_loss: 14.3479\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2254 - val_loss: 14.3279\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2139 - val_loss: 14.3374\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2263 - val_loss: 14.2970\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 23s 9ms/step - loss: 16.2145 - val_loss: 14.3424\n",
      "4148/4148 [==============================] - 6s 2ms/step\n",
      "RMSE on valid data: 3.7795021868434033\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 290,049\n",
      "Trainable params: 288,321\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 44s 16ms/step - loss: 17.7297 - val_loss: 13.7774\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 43s 16ms/step - loss: 15.6711 - val_loss: 14.0913\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 42s 16ms/step - loss: 15.4862 - val_loss: 13.9935\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 42s 16ms/step - loss: 15.3545 - val_loss: 13.8549\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 42s 16ms/step - loss: 15.2484 - val_loss: 13.9896\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 42s 16ms/step - loss: 15.1025 - val_loss: 13.7231\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 42s 16ms/step - loss: 14.9927 - val_loss: 14.1457\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 42s 16ms/step - loss: 14.8904 - val_loss: 14.5226\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 42s 16ms/step - loss: 14.7566 - val_loss: 14.8114\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 42s 16ms/step - loss: 14.6260 - val_loss: 14.6778\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 42s 16ms/step - loss: 14.5479 - val_loss: 17.0847\n",
      "4148/4148 [==============================] - 10s 2ms/step\n",
      "RMSE on valid data: 3.704475044849236\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 290,049\n",
      "Trainable params: 288,321\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 42s 15ms/step - loss: 17.6943 - val_loss: 13.7688\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.7068 - val_loss: 13.6654\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.5515 - val_loss: 13.5732\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.4629 - val_loss: 13.7152\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.4063 - val_loss: 13.5372\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.3558 - val_loss: 13.5892\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.3214 - val_loss: 13.5195\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.2646 - val_loss: 13.5670\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.2479 - val_loss: 13.6007\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.1832 - val_loss: 13.4750\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.1662 - val_loss: 13.4808\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.1463 - val_loss: 13.4634\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.1082 - val_loss: 13.5307\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.0883 - val_loss: 13.5435\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.0591 - val_loss: 13.4508\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.0448 - val_loss: 13.4427\n",
      "Epoch 17/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.0089 - val_loss: 13.4519\n",
      "Epoch 18/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 15.0005 - val_loss: 13.4034\n",
      "Epoch 19/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 14.9919 - val_loss: 13.4084\n",
      "Epoch 20/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 14.9494 - val_loss: 13.4077\n",
      "Epoch 21/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 14.9258 - val_loss: 13.5114\n",
      "Epoch 22/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 14.9020 - val_loss: 13.4520\n",
      "Epoch 23/100\n",
      "2655/2655 [==============================] - 40s 15ms/step - loss: 14.8906 - val_loss: 13.4460\n",
      "4148/4148 [==============================] - 9s 2ms/step\n",
      "RMSE on valid data: 3.661063630899902\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               136704    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 290,049\n",
      "Trainable params: 288,321\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2655/2655 [==============================] - 34s 12ms/step - loss: 18.0059 - val_loss: 14.4222\n",
      "Epoch 2/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.3460 - val_loss: 14.3949\n",
      "Epoch 3/100\n",
      "2655/2655 [==============================] - 33s 12ms/step - loss: 16.2848 - val_loss: 14.4565\n",
      "Epoch 4/100\n",
      "2655/2655 [==============================] - 33s 12ms/step - loss: 16.2111 - val_loss: 14.3415\n",
      "Epoch 5/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1750 - val_loss: 14.4261\n",
      "Epoch 6/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1576 - val_loss: 14.3794\n",
      "Epoch 7/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1498 - val_loss: 14.3015\n",
      "Epoch 8/100\n",
      "2655/2655 [==============================] - 33s 12ms/step - loss: 16.1464 - val_loss: 14.3242\n",
      "Epoch 9/100\n",
      "2655/2655 [==============================] - 33s 12ms/step - loss: 16.1306 - val_loss: 14.3108\n",
      "Epoch 10/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1272 - val_loss: 14.4974\n",
      "Epoch 11/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1275 - val_loss: 14.2910\n",
      "Epoch 12/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1150 - val_loss: 14.3157\n",
      "Epoch 13/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1207 - val_loss: 14.2929\n",
      "Epoch 14/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1106 - val_loss: 14.3554\n",
      "Epoch 15/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1107 - val_loss: 14.3148\n",
      "Epoch 16/100\n",
      "2655/2655 [==============================] - 32s 12ms/step - loss: 16.1143 - val_loss: 14.3261\n",
      "4148/4148 [==============================] - 8s 2ms/step\n",
      "RMSE on valid data: 3.7803443950660776\n"
     ]
    }
   ],
   "source": [
    "mod4 = train_nn(neurons, activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10d084",
   "metadata": {},
   "source": [
    "## Retrain on train + valid data and evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0e4a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain network\n",
    "X_train2 = pd.concat([X_train, X_valid])\n",
    "y_train2 = pd.concat([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c12884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((530840, 266), (132711, 266), (530840,), (132711,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, X_test.shape, y_train2.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66554544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model\n",
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1], activation = keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation = keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16, activation = keras.layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=1, activation = 'linear'))\n",
    "    model.compile(loss='mse', optimizer= 'adam' )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46b5f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 128)               34176     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,321\n",
      "Trainable params: 43,905\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/19\n",
      "3539/3539 [==============================] - 8s 2ms/step - loss: 16.8586\n",
      "Epoch 2/19\n",
      "3539/3539 [==============================] - 8s 2ms/step - loss: 14.9691\n",
      "Epoch 3/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.8627\n",
      "Epoch 4/19\n",
      "3539/3539 [==============================] - 8s 2ms/step - loss: 14.7972\n",
      "Epoch 5/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.7450\n",
      "Epoch 6/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.6951\n",
      "Epoch 7/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.6569\n",
      "Epoch 8/19\n",
      "3539/3539 [==============================] - 8s 2ms/step - loss: 14.6229\n",
      "Epoch 9/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.5901\n",
      "Epoch 10/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.5614\n",
      "Epoch 11/19\n",
      "3539/3539 [==============================] - 8s 2ms/step - loss: 14.5394\n",
      "Epoch 12/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.4951\n",
      "Epoch 13/19\n",
      "3539/3539 [==============================] - 8s 2ms/step - loss: 14.4680\n",
      "Epoch 14/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.4507\n",
      "Epoch 15/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.4195\n",
      "Epoch 16/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.3867\n",
      "Epoch 17/19\n",
      "3539/3539 [==============================] - 8s 2ms/step - loss: 14.3599\n",
      "Epoch 18/19\n",
      "3539/3539 [==============================] - 7s 2ms/step - loss: 14.3452\n",
      "Epoch 19/19\n",
      "3539/3539 [==============================] - 8s 2ms/step - loss: 14.3121\n",
      "4148/4148 [==============================] - 4s 846us/step\n",
      "RMSE on test data: 3.8557453971900504\n",
      "MAE on test data: 1.31755092081832\n"
     ]
    }
   ],
   "source": [
    "nn_mod = nn_model()\n",
    "print(nn_mod.summary())\n",
    "nn_mod.fit(X_train2, y_train2, batch_size = 150, epochs = 19)\n",
    "pred = nn_mod.predict(X_test)\n",
    "print('RMSE on test data:', sqrt(mse(y_test, pred)))\n",
    "print('MAE on test data:', mae(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70e6f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame()\n",
    "error_df['NN_true'] = y_test\n",
    "error_df['NN_predicted'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49bedd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df['error'] = error_df['NN_true'] - error_df['NN_predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03863807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217d46a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = sns.scatterplot(data = error_df, x = 'NN_predicted', y = 'NN_true', color = 'b')\n",
    "#plt.axhline(y = 0, color = 'r')\n",
    "plt.plot([-1, 120], [-1, 120], c = 'r')\n",
    "plt.title('Feedforward Neural Network without Entity Embeddings')\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')\n",
    "plt.savefig('NN_errors.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd9ee51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.to_csv('NN_errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6c6b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of epochs\n",
    "loss = [18.3565, 15.699, 15.5651, 15.4852, 15.4442, 15.4096, 15.3822, 15.3546, 15.3422, 15.3130, 15.2964, 15.2840, 15.2732, 15.2515, 15.2426, 15.2193, 15.2143, 15.2009, 15.1863, 15.1788, 15.1809, 15.1839, 15.1683, 15.1385]\n",
    "val_loss = [13.7413, 13.7285, 13.6259, 13.5764, 13.6047, 13.6029, 13.5317, 13.5272, 13.5001, 13.5139, 13.4928, 13.4980, 13.4977, 13.4929, 13.5003, 13.4699, 13.5577, 13.4911, 13.4498, 13.5046, 13.5147, 13.4583, 13.4660, 13.4596]\n",
    "loss = [sqrt(x) for x in loss]\n",
    "val_loss = [sqrt(x) for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8136eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Model Loss of the Neural Network')\n",
    "plt.ylabel('loss (RMSE)')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.legend(['Train', 'Valid'], loc='upper right')\n",
    "plt.xticks([-1, 4, 9, 14, 19], [0, 5, 10, 15, 20])\n",
    "plt.savefig('ModelLossNNwoutEE.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf65e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
